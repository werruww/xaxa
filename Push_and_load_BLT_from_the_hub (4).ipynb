{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Set-up environment"
      ],
      "metadata": {
        "id": "BvbBOQvU7z5Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "g6s5QCyV7u01",
        "outputId": "f8977f27-343f-46a2-e7e1-4e901f41e903"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'blt'...\n",
            "remote: Enumerating objects: 538, done.\u001b[K\n",
            "remote: Counting objects: 100% (204/204), done.\u001b[K\n",
            "remote: Compressing objects: 100% (117/117), done.\u001b[K\n",
            "remote: Total 538 (delta 148), reused 102 (delta 87), pack-reused 334 (from 2)\u001b[K\n",
            "Receiving objects: 100% (538/538), 476.65 KiB | 10.36 MiB/s, done.\n",
            "Resolving deltas: 100% (305/305), done.\n",
            "/content/blt\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.0.2)\n",
            "Collecting omegaconf (from -r requirements.txt (line 2))\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting msgspec (from -r requirements.txt (line 3))\n",
            "  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting rouge-score (from -r requirements.txt (line 4))\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sacrebleu (from -r requirements.txt (line 5))\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (0.2.0)\n",
            "Collecting tiktoken (from -r requirements.txt (line 7))\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (2025.3.2)\n",
            "Collecting blobfile (from -r requirements.txt (line 9))\n",
            "  Downloading blobfile-3.0.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (0.19.9)\n",
            "Collecting viztracer (from -r requirements.txt (line 11))\n",
            "  Downloading viztracer-1.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (26 kB)\n",
            "Collecting lm-eval (from -r requirements.txt (line 12))\n",
            "  Downloading lm_eval-0.4.8-py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (1.14.1)\n",
            "Requirement already satisfied: pynvml in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (12.0.0)\n",
            "Collecting datatrove (from -r requirements.txt (line 15))\n",
            "  Downloading datatrove-0.4.0-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (3.10.16)\n",
            "Collecting luigi (from -r requirements.txt (line 17))\n",
            "  Downloading luigi-3.6.0.tar.gz (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 18)) (2.11.3)\n",
            "Requirement already satisfied: altair in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (5.5.0)\n",
            "Collecting submitit (from -r requirements.txt (line 20))\n",
            "  Downloading submitit-1.5.2-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 21)) (0.15.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 22)) (13.9.4)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf->-r requirements.txt (line 2))\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from omegaconf->-r requirements.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score->-r requirements.txt (line 4)) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score->-r requirements.txt (line 4)) (3.9.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score->-r requirements.txt (line 4)) (1.17.0)\n",
            "Collecting portalocker (from sacrebleu->-r requirements.txt (line 5))\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu->-r requirements.txt (line 5)) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu->-r requirements.txt (line 5)) (0.9.0)\n",
            "Collecting colorama (from sacrebleu->-r requirements.txt (line 5))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu->-r requirements.txt (line 5)) (5.3.2)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->-r requirements.txt (line 7)) (2.32.3)\n",
            "Collecting pycryptodomex>=3.8 (from blobfile->-r requirements.txt (line 9))\n",
            "  Downloading pycryptodomex-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.25.3 in /usr/local/lib/python3.11/dist-packages (from blobfile->-r requirements.txt (line 9)) (2.3.0)\n",
            "Requirement already satisfied: filelock>=3.0 in /usr/local/lib/python3.11/dist-packages (from blobfile->-r requirements.txt (line 9)) (3.18.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 10)) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 10)) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 10)) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 10)) (4.3.7)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 10)) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 10)) (2.26.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 10)) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 10)) (75.2.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 10)) (4.13.2)\n",
            "Collecting objprint>=0.3.0 (from viztracer->-r requirements.txt (line 11))\n",
            "  Downloading objprint-0.3.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from lm-eval->-r requirements.txt (line 12)) (1.5.2)\n",
            "Collecting evaluate (from lm-eval->-r requirements.txt (line 12))\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting datasets>=2.16.0 (from lm-eval->-r requirements.txt (line 12))\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting jsonlines (from lm-eval->-r requirements.txt (line 12))\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from lm-eval->-r requirements.txt (line 12)) (2.10.2)\n",
            "Requirement already satisfied: peft>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from lm-eval->-r requirements.txt (line 12)) (0.14.0)\n",
            "Collecting pybind11>=2.6.2 (from lm-eval->-r requirements.txt (line 12))\n",
            "  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting pytablewriter (from lm-eval->-r requirements.txt (line 12))\n",
            "  Downloading pytablewriter-1.2.1-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from lm-eval->-r requirements.txt (line 12)) (1.6.1)\n",
            "Collecting sqlitedict (from lm-eval->-r requirements.txt (line 12))\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.11/dist-packages (from lm-eval->-r requirements.txt (line 12)) (2.6.0+cu124)\n",
            "Collecting tqdm-multiprocess (from lm-eval->-r requirements.txt (line 12))\n",
            "  Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: transformers>=4.1 in /usr/local/lib/python3.11/dist-packages (from lm-eval->-r requirements.txt (line 12)) (4.51.3)\n",
            "Requirement already satisfied: zstandard in /usr/local/lib/python3.11/dist-packages (from lm-eval->-r requirements.txt (line 12)) (0.23.0)\n",
            "Collecting dill (from lm-eval->-r requirements.txt (line 12))\n",
            "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting word2number (from lm-eval->-r requirements.txt (line 12))\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more_itertools in /usr/local/lib/python3.11/dist-packages (from lm-eval->-r requirements.txt (line 12)) (10.6.0)\n",
            "Requirement already satisfied: nvidia-ml-py<13.0.0a0,>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from pynvml->-r requirements.txt (line 14)) (12.570.86)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.11/dist-packages (from datatrove->-r requirements.txt (line 15)) (0.30.2)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.11/dist-packages (from datatrove->-r requirements.txt (line 15)) (4.12.2)\n",
            "Collecting loguru>=0.7.0 (from datatrove->-r requirements.txt (line 15))\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting multiprocess (from datatrove->-r requirements.txt (line 15))\n",
            "  Downloading multiprocess-0.70.18-py311-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from datatrove->-r requirements.txt (line 15)) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.5 in /usr/local/lib/python3.11/dist-packages (from luigi->-r requirements.txt (line 17)) (2.8.2)\n",
            "Collecting tenacity<9,>=8 (from luigi->-r requirements.txt (line 17))\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: tornado<7,>=5.0 in /usr/local/lib/python3.11/dist-packages (from luigi->-r requirements.txt (line 17)) (6.4.2)\n",
            "Collecting python-daemon (from luigi->-r requirements.txt (line 17))\n",
            "  Downloading python_daemon-3.1.2-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->-r requirements.txt (line 18)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic->-r requirements.txt (line 18)) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->-r requirements.txt (line 18)) (0.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair->-r requirements.txt (line 19)) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair->-r requirements.txt (line 19)) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair->-r requirements.txt (line 19)) (1.35.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from altair->-r requirements.txt (line 19)) (24.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from submitit->-r requirements.txt (line 20)) (3.1.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer->-r requirements.txt (line 21)) (1.5.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->-r requirements.txt (line 22)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->-r requirements.txt (line 22)) (2.18.0)\n",
            "Collecting adlfs (from fsspec[full]->-r requirements.txt (line 23))\n",
            "  Downloading adlfs-2024.12.0-py3-none-any.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[full]->-r requirements.txt (line 23)) (3.11.15)\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.11/dist-packages (from fsspec[full]->-r requirements.txt (line 23)) (2024.12.1)\n",
            "Requirement already satisfied: distributed in /usr/local/lib/python3.11/dist-packages (from fsspec[full]->-r requirements.txt (line 23)) (2024.12.1)\n",
            "Collecting dropbox (from fsspec[full]->-r requirements.txt (line 23))\n",
            "  Downloading dropbox-12.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting dropboxdrivefs (from fsspec[full]->-r requirements.txt (line 23))\n",
            "  Downloading dropboxdrivefs-1.4.1.tar.gz (7.4 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fusepy (from fsspec[full]->-r requirements.txt (line 23))\n",
            "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gcsfs in /usr/local/lib/python3.11/dist-packages (from fsspec[full]->-r requirements.txt (line 23)) (2025.3.2)\n",
            "Collecting libarchive-c (from fsspec[full]->-r requirements.txt (line 23))\n",
            "  Downloading libarchive_c-5.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting ocifs (from fsspec[full]->-r requirements.txt (line 23))\n",
            "  Downloading ocifs-1.3.2-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: panel in /usr/local/lib/python3.11/dist-packages (from fsspec[full]->-r requirements.txt (line 23)) (1.6.2)\n",
            "Collecting paramiko (from fsspec[full]->-r requirements.txt (line 23))\n",
            "  Downloading paramiko-3.5.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: pyarrow>=1 in /usr/local/lib/python3.11/dist-packages (from fsspec[full]->-r requirements.txt (line 23)) (18.1.0)\n",
            "Requirement already satisfied: pygit2 in /usr/local/lib/python3.11/dist-packages (from fsspec[full]->-r requirements.txt (line 23)) (1.17.0)\n",
            "Collecting s3fs (from fsspec[full]->-r requirements.txt (line 23))\n",
            "  Downloading s3fs-2025.3.2-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting smbprotocol (from fsspec[full]->-r requirements.txt (line 23))\n",
            "  Downloading smbprotocol-1.15.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm-eval->-r requirements.txt (line 12)) (0.5.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[full]->-r requirements.txt (line 23)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[full]->-r requirements.txt (line 23)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[full]->-r requirements.txt (line 23)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[full]->-r requirements.txt (line 23)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[full]->-r requirements.txt (line 23)) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[full]->-r requirements.txt (line 23)) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[full]->-r requirements.txt (line 23)) (1.19.0)\n",
            "Collecting dill (from lm-eval->-r requirements.txt (line 12))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm-eval->-r requirements.txt (line 12)) (2.2.2)\n",
            "Collecting xxhash (from datasets>=2.16.0->lm-eval->-r requirements.txt (line 12))\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datatrove->-r requirements.txt (line 15))\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "INFO: pip is looking at multiple versions of datasets to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting datasets>=2.16.0 (from lm-eval->-r requirements.txt (line 12))\n",
            "  Downloading datasets-3.4.1-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-3.4.0-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-3.3.1-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-3.3.0-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "INFO: pip is still looking at multiple versions of datasets to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading datasets-3.0.2-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading datasets-3.0.0-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting pyarrow-hotfix (from datasets>=2.16.0->lm-eval->-r requirements.txt (line 12))\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting datasets>=2.16.0 (from lm-eval->-r requirements.txt (line 12))\n",
            "  Downloading datasets-2.19.2-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-2.19.0-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading datasets-2.17.1-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading datasets-2.17.0-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading datasets-2.16.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting dill (from lm-eval->-r requirements.txt (line 12))\n",
            "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting datasets>=2.16.0 (from lm-eval->-r requirements.txt (line 12))\n",
            "  Downloading datasets-2.16.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting fsspec[full] (from -r requirements.txt (line 23))\n",
            "  Downloading fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "  Downloading fsspec-2025.2.0-py3-none-any.whl.metadata (11 kB)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 10)) (4.0.12)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair->-r requirements.txt (line 19)) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair->-r requirements.txt (line 19)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair->-r requirements.txt (line 19)) (0.24.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->-r requirements.txt (line 22)) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->-r requirements.txt (line 7)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->-r requirements.txt (line 7)) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->-r requirements.txt (line 7)) (2025.1.31)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.1->lm-eval->-r requirements.txt (line 12)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.1->lm-eval->-r requirements.txt (line 12)) (3.6.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval->-r requirements.txt (line 12)) (3.4.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8->lm-eval->-r requirements.txt (line 12))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8->lm-eval->-r requirements.txt (line 12))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8->lm-eval->-r requirements.txt (line 12))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8->lm-eval->-r requirements.txt (line 12))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8->lm-eval->-r requirements.txt (line 12))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8->lm-eval->-r requirements.txt (line 12))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8->lm-eval->-r requirements.txt (line 12))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8->lm-eval->-r requirements.txt (line 12))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8->lm-eval->-r requirements.txt (line 12))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval->-r requirements.txt (line 12)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval->-r requirements.txt (line 12)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval->-r requirements.txt (line 12)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8->lm-eval->-r requirements.txt (line 12))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval->-r requirements.txt (line 12)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval->-r requirements.txt (line 12)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8->lm-eval->-r requirements.txt (line 12)) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.1->lm-eval->-r requirements.txt (line 12)) (0.21.1)\n",
            "Collecting azure-core<2.0.0,>=1.28.0 (from adlfs->fsspec[full]->-r requirements.txt (line 23))\n",
            "  Downloading azure_core-1.33.0-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-datalake-store<0.1,>=0.0.53 (from adlfs->fsspec[full]->-r requirements.txt (line 23))\n",
            "  Downloading azure_datalake_store-0.0.53-py2.py3-none-any.whl.metadata (19 kB)\n",
            "Collecting azure-identity (from adlfs->fsspec[full]->-r requirements.txt (line 23))\n",
            "  Downloading azure_identity-1.21.0-py3-none-any.whl.metadata (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-storage-blob>=12.17.0 (from adlfs->fsspec[full]->-r requirements.txt (line 23))\n",
            "  Downloading azure_storage_blob-12.25.1-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from dask->fsspec[full]->-r requirements.txt (line 23)) (1.4.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from dask->fsspec[full]->-r requirements.txt (line 23)) (0.12.1)\n",
            "Requirement already satisfied: importlib_metadata>=4.13.0 in /usr/local/lib/python3.11/dist-packages (from dask->fsspec[full]->-r requirements.txt (line 23)) (8.6.1)\n",
            "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from distributed->fsspec[full]->-r requirements.txt (line 23)) (1.0.0)\n",
            "Requirement already satisfied: msgpack>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from distributed->fsspec[full]->-r requirements.txt (line 23)) (1.1.0)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.11/dist-packages (from distributed->fsspec[full]->-r requirements.txt (line 23)) (2.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from distributed->fsspec[full]->-r requirements.txt (line 23)) (3.1.0)\n",
            "Requirement already satisfied: zict>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from distributed->fsspec[full]->-r requirements.txt (line 23)) (3.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair->-r requirements.txt (line 19)) (3.0.2)\n",
            "Collecting stone<3.3.3,>=2 (from dropbox->fsspec[full]->-r requirements.txt (line 23))\n",
            "  Downloading stone-3.3.1-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.11/dist-packages (from gcsfs->fsspec[full]->-r requirements.txt (line 23)) (4.4.2)\n",
            "INFO: pip is looking at multiple versions of gcsfs to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting gcsfs (from fsspec[full]->-r requirements.txt (line 23))\n",
            "  Downloading gcsfs-2025.3.1-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading gcsfs-2025.3.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading gcsfs-2025.2.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading gcsfs-2024.12.0-py2.py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.11/dist-packages (from gcsfs->fsspec[full]->-r requirements.txt (line 23)) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.11/dist-packages (from gcsfs->fsspec[full]->-r requirements.txt (line 23)) (1.2.1)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.11/dist-packages (from gcsfs->fsspec[full]->-r requirements.txt (line 23)) (2.19.0)\n",
            "Collecting oci>=2.43.1 (from ocifs->fsspec[full]->-r requirements.txt (line 23))\n",
            "  Downloading oci-2.150.2-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from panel->fsspec[full]->-r requirements.txt (line 23)) (6.2.0)\n",
            "Requirement already satisfied: bokeh<3.8.0,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from panel->fsspec[full]->-r requirements.txt (line 23)) (3.6.3)\n",
            "Requirement already satisfied: linkify-it-py in /usr/local/lib/python3.11/dist-packages (from panel->fsspec[full]->-r requirements.txt (line 23)) (2.0.3)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.11/dist-packages (from panel->fsspec[full]->-r requirements.txt (line 23)) (3.8)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.11/dist-packages (from panel->fsspec[full]->-r requirements.txt (line 23)) (0.4.2)\n",
            "Requirement already satisfied: param<3.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from panel->fsspec[full]->-r requirements.txt (line 23)) (2.2.0)\n",
            "Requirement already satisfied: pyviz-comms>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from panel->fsspec[full]->-r requirements.txt (line 23)) (3.0.4)\n",
            "Collecting bcrypt>=3.2 (from paramiko->fsspec[full]->-r requirements.txt (line 23))\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: cryptography>=3.3 in /usr/local/lib/python3.11/dist-packages (from paramiko->fsspec[full]->-r requirements.txt (line 23)) (43.0.3)\n",
            "Collecting pynacl>=1.5 (from paramiko->fsspec[full]->-r requirements.txt (line 23))\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: cffi>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from pygit2->fsspec[full]->-r requirements.txt (line 23)) (1.17.1)\n",
            "Collecting DataProperty<2,>=1.1.0 (from pytablewriter->lm-eval->-r requirements.txt (line 12))\n",
            "  Downloading DataProperty-1.1.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm-eval->-r requirements.txt (line 12))\n",
            "  Downloading mbstrdecoder-1.1.4-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm-eval->-r requirements.txt (line 12))\n",
            "  Downloading pathvalidate-3.2.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting tabledata<2,>=1.3.1 (from pytablewriter->lm-eval->-r requirements.txt (line 12))\n",
            "  Downloading tabledata-1.3.4-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm-eval->-r requirements.txt (line 12))\n",
            "  Downloading tcolorpy-0.1.7-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting typepy<2,>=1.3.2 (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval->-r requirements.txt (line 12))\n",
            "  Downloading typepy-1.3.4-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting lockfile>=0.10 (from python-daemon->luigi->-r requirements.txt (line 17))\n",
            "  Downloading lockfile-0.12.2-py2.py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting aiobotocore<3.0.0,>=2.5.4 (from s3fs->fsspec[full]->-r requirements.txt (line 23))\n",
            "  Downloading aiobotocore-2.21.1-py3-none-any.whl.metadata (24 kB)\n",
            "INFO: pip is looking at multiple versions of s3fs to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting s3fs (from fsspec[full]->-r requirements.txt (line 23))\n",
            "  Downloading s3fs-2025.3.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading s3fs-2025.3.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading s3fs-2025.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Downloading s3fs-2024.12.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting pyspnego (from smbprotocol->fsspec[full]->-r requirements.txt (line 23))\n",
            "  Downloading pyspnego-0.11.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs->fsspec[full]->-r requirements.txt (line 23))\n",
            "  Downloading aioitertools-0.12.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting botocore<1.37.2,>=1.37.0 (from aiobotocore<3.0.0,>=2.5.4->s3fs->fsspec[full]->-r requirements.txt (line 23))\n",
            "  Downloading botocore-1.37.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs->fsspec[full]->-r requirements.txt (line 23))\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /usr/local/lib/python3.11/dist-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs->fsspec[full]->-r requirements.txt (line 23)) (1.17.2)\n",
            "Collecting msal<2,>=1.16.0 (from azure-datalake-store<0.1,>=0.0.53->adlfs->fsspec[full]->-r requirements.txt (line 23))\n",
            "  Downloading msal-1.32.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting isodate>=0.6.1 (from azure-storage-blob>=12.17.0->adlfs->fsspec[full]->-r requirements.txt (line 23))\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.11/dist-packages (from bokeh<3.8.0,>=3.5.0->panel->fsspec[full]->-r requirements.txt (line 23)) (1.3.2)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from bokeh<3.8.0,>=3.5.0->panel->fsspec[full]->-r requirements.txt (line 23)) (11.1.0)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.11/dist-packages (from bokeh<3.8.0,>=3.5.0->panel->fsspec[full]->-r requirements.txt (line 23)) (2025.1.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.17.0->pygit2->fsspec[full]->-r requirements.txt (line 23)) (2.22)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 10)) (5.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.2->gcsfs->fsspec[full]->-r requirements.txt (line 23)) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.2->gcsfs->fsspec[full]->-r requirements.txt (line 23)) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.2->gcsfs->fsspec[full]->-r requirements.txt (line 23)) (4.9.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.13.0->dask->fsspec[full]->-r requirements.txt (line 23)) (3.21.0)\n",
            "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.11/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm-eval->-r requirements.txt (line 12)) (5.2.0)\n",
            "Requirement already satisfied: pyOpenSSL<25.0.0,>=17.5.0 in /usr/local/lib/python3.11/dist-packages (from oci>=2.43.1->ocifs->fsspec[full]->-r requirements.txt (line 23)) (24.2.1)\n",
            "Requirement already satisfied: pytz>=2016.10 in /usr/local/lib/python3.11/dist-packages (from oci>=2.43.1->ocifs->fsspec[full]->-r requirements.txt (line 23)) (2025.2)\n",
            "Collecting circuitbreaker<3.0.0,>=1.3.1 (from oci>=2.43.1->ocifs->fsspec[full]->-r requirements.txt (line 23))\n",
            "  Downloading circuitbreaker-2.1.3-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.16.0->lm-eval->-r requirements.txt (line 12)) (2025.2)\n",
            "Requirement already satisfied: ply>=3.4 in /usr/local/lib/python3.11/dist-packages (from stone<3.3.3,>=2->dropbox->fsspec[full]->-r requirements.txt (line 23)) (3.11)\n",
            "Collecting msal-extensions>=1.2.0 (from azure-identity->adlfs->fsspec[full]->-r requirements.txt (line 23))\n",
            "  Downloading msal_extensions-1.3.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach->panel->fsspec[full]->-r requirements.txt (line 23)) (0.5.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib->gcsfs->fsspec[full]->-r requirements.txt (line 23)) (2.0.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs->fsspec[full]->-r requirements.txt (line 23)) (2.24.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs->fsspec[full]->-r requirements.txt (line 23)) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs->fsspec[full]->-r requirements.txt (line 23)) (2.7.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs->fsspec[full]->-r requirements.txt (line 23)) (1.7.1)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.11/dist-packages (from linkify-it-py->panel->fsspec[full]->-r requirements.txt (line 23)) (1.0.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs->fsspec[full]->-r requirements.txt (line 23)) (1.70.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs->fsspec[full]->-r requirements.txt (line 23)) (1.26.1)\n",
            "Requirement already satisfied: PyJWT<3,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from PyJWT[crypto]<3,>=1.0.0->msal<2,>=1.16.0->azure-datalake-store<0.1,>=0.0.53->adlfs->fsspec[full]->-r requirements.txt (line 23)) (2.10.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs->fsspec[full]->-r requirements.txt (line 23)) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs->fsspec[full]->-r requirements.txt (line 23)) (3.2.2)\n",
            "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blobfile-3.0.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading viztracer-1.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lm_eval-0.4.8-py3-none-any.whl (3.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m95.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datatrove-0.4.0-py3-none-any.whl (17.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.2/17.2 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading submitit-1.5.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.9/74.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading objprint-0.3.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodomex-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading adlfs-2024.12.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading dropbox-12.0.2-py3-none-any.whl (572 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m572.1/572.1 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gcsfs-2024.12.0-py2.py3-none-any.whl (35 kB)\n",
            "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Downloading libarchive_c-5.2-py3-none-any.whl (15 kB)\n",
            "Downloading ocifs-1.3.2-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading paramiko-3.5.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.3/227.3 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Downloading pytablewriter-1.2.1-py3-none-any.whl (91 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.1/91.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_daemon-3.1.2-py3-none-any.whl (30 kB)\n",
            "Downloading s3fs-2024.12.0-py3-none-any.whl (30 kB)\n",
            "Downloading smbprotocol-1.15.0-py3-none-any.whl (126 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\n",
            "Downloading aiobotocore-2.21.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_core-1.33.0-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.1/207.1 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_datalake_store-0.0.53-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_storage_blob-12.25.1-py3-none-any.whl (406 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.0/407.0 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading DataProperty-1.1.0-py3-none-any.whl (27 kB)\n",
            "Downloading lockfile-0.12.2-py2.py3-none-any.whl (13 kB)\n",
            "Downloading mbstrdecoder-1.1.4-py3-none-any.whl (7.9 kB)\n",
            "Downloading oci-2.150.2-py3-none-any.whl (29.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.8/29.8 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pathvalidate-3.2.3-py3-none-any.whl (24 kB)\n",
            "Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stone-3.3.1-py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.3/162.3 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tabledata-1.3.4-py3-none-any.whl (11 kB)\n",
            "Downloading tcolorpy-0.1.7-py3-none-any.whl (8.1 kB)\n",
            "Downloading typepy-1.3.4-py3-none-any.whl (31 kB)\n",
            "Downloading azure_identity-1.21.0-py3-none-any.whl (189 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.2/189.2 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyspnego-0.11.2-py3-none-any.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aioitertools-0.12.0-py3-none-any.whl (24 kB)\n",
            "Downloading botocore-1.37.1-py3-none-any.whl (13.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading circuitbreaker-2.1.3-py3-none-any.whl (7.7 kB)\n",
            "Downloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading msal-1.32.0-py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.7/114.7 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msal_extensions-1.3.1-py3-none-any.whl (20 kB)\n",
            "Building wheels for collected packages: antlr4-python3-runtime, rouge-score, luigi, dropboxdrivefs, fusepy, sqlitedict, word2number\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=031d13d3af3e5f64386ab09b33616d9155a98009012daec6f646fe51310b03df\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=5b0d2a420d99cee474a6a7acf65932f9bbc2f2de1b6894a866fa13c3d8c1f2ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
            "  Building wheel for luigi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for luigi: filename=luigi-3.6.0-py3-none-any.whl size=1093756 sha256=be65b7aecaa2389742e13e0772bbc36b0a643e8cb1c1ee26c03c07c8def161f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/22/3c/af6674483adf7af53c451451c24b1e330e00b6fe1cc70bb96a\n",
            "  Building wheel for dropboxdrivefs (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dropboxdrivefs: filename=dropboxdrivefs-1.4.1-py3-none-any.whl size=8240 sha256=59a5979b2b202068e7a6235a2528aefa76a3ac1d0f9672a46f2bc92c24478586\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/fd/ae/739b6fd4bbedc3c90dd265e6c4719ccd861cd7519fc49c1f06\n",
            "  Building wheel for fusepy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10486 sha256=32ee860d7e8095104d691428f792f80a97d152501fa102d181a43ff460632627\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/4a/86/fdda91f8b8ebb0a70e4181dc2423b1f70c3c2d3bd1158685b5\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16862 sha256=091f64e38a839a7c3241c954bec60c3cdcc1c11251c23a01cc0a9a1a06a104ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/63/89/7210274f9b7fb033b8f22671f64c0e0b55083d30c3c046a3ff\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5568 sha256=94b1ef8a8edc2b9ff0c7ea3bb409dfb361abc80de9d24cb6b568a8ffe20c7f72\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/ef/ae/073b491b14d25e2efafcffca9e16b2ee6d114ec5c643ba4f06\n",
            "Successfully built antlr4-python3-runtime rouge-score luigi dropboxdrivefs fusepy sqlitedict word2number\n",
            "Installing collected packages: word2number, sqlitedict, lockfile, libarchive-c, fusepy, circuitbreaker, antlr4-python3-runtime, xxhash, tenacity, tcolorpy, submitit, stone, python-daemon, pycryptodomex, pybind11, portalocker, pathvalidate, omegaconf, objprint, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, msgspec, mbstrdecoder, loguru, jsonlines, jmespath, isodate, fsspec, dill, colorama, bcrypt, aioitertools, viztracer, typepy, tqdm-multiprocess, tiktoken, sacrebleu, rouge-score, pynacl, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, luigi, dropbox, botocore, blobfile, azure-core, pyspnego, paramiko, nvidia-cusolver-cu12, dropboxdrivefs, datatrove, azure-storage-blob, aiobotocore, smbprotocol, s3fs, oci, msal, datasets, DataProperty, tabledata, ocifs, msal-extensions, evaluate, azure-datalake-store, pytablewriter, gcsfs, azure-identity, lm-eval, adlfs\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.1.2\n",
            "    Uninstalling tenacity-9.1.2:\n",
            "      Successfully uninstalled tenacity-9.1.2\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: gcsfs\n",
            "    Found existing installation: gcsfs 2025.3.2\n",
            "    Uninstalling gcsfs-2025.3.2:\n",
            "      Successfully uninstalled gcsfs-2025.3.2\n",
            "Successfully installed DataProperty-1.1.0 adlfs-2024.12.0 aiobotocore-2.21.1 aioitertools-0.12.0 antlr4-python3-runtime-4.9.3 azure-core-1.33.0 azure-datalake-store-0.0.53 azure-identity-1.21.0 azure-storage-blob-12.25.1 bcrypt-4.3.0 blobfile-3.0.0 botocore-1.37.1 circuitbreaker-2.1.3 colorama-0.4.6 datasets-3.5.0 datatrove-0.4.0 dill-0.3.8 dropbox-12.0.2 dropboxdrivefs-1.4.1 evaluate-0.4.3 fsspec-2024.12.0 fusepy-3.0.1 gcsfs-2024.12.0 isodate-0.7.2 jmespath-1.0.1 jsonlines-4.0.0 libarchive-c-5.2 lm-eval-0.4.8 lockfile-0.12.2 loguru-0.7.3 luigi-3.6.0 mbstrdecoder-1.1.4 msal-1.32.0 msal-extensions-1.3.1 msgspec-0.19.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 objprint-0.3.0 oci-2.150.2 ocifs-1.3.2 omegaconf-2.3.0 paramiko-3.5.1 pathvalidate-3.2.3 portalocker-3.1.1 pybind11-2.13.6 pycryptodomex-3.22.0 pynacl-1.5.0 pyspnego-0.11.2 pytablewriter-1.2.1 python-daemon-3.1.2 rouge-score-0.1.2 s3fs-2024.12.0 sacrebleu-2.5.1 smbprotocol-1.15.0 sqlitedict-2.1.0 stone-3.3.1 submitit-1.5.2 tabledata-1.3.4 tcolorpy-0.1.7 tenacity-8.5.0 tiktoken-0.9.0 tqdm-multiprocess-0.0.11 typepy-1.3.4 viztracer-1.0.3 word2number-1.1 xxhash-3.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "35ff63a972a6440d8a8dd33a479d39ec"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!git clone -b add_mixin https://github.com/nielsrogge/blt\n",
        "%cd blt\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade huggingface_hub"
      ],
      "metadata": {
        "id": "FWnPPv8-NYO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load model"
      ],
      "metadata": {
        "id": "Cw-HfABp8PCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bytelatent.generate import load_consolidated_model_and_tokenizer\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "checkpoint_path = hf_hub_download(repo_id=\"facebook/blt-1b\", filename=\"consolidated.pth\")\n",
        "\n",
        "model, tokenizer, train_cfg = load_consolidated_model_and_tokenizer(checkpoint_path)"
      ],
      "metadata": {
        "id": "pibqmwDq74Jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Push to the hub"
      ],
      "metadata": {
        "id": "vqoF3xk58lyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.push_to_hub(\"facebook/blt-1b\")"
      ],
      "metadata": {
        "id": "VC0TdW4J8m1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reload\n",
        "\n",
        "Now anyone can use the model like so:"
      ],
      "metadata": {
        "id": "UZGg4-Ys8o-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bytelatent.model.blt import ByteLatentTransformer\n",
        "\n",
        "model = ByteLatentTransformer.from_pretrained(\"facebook/blt-1b\")"
      ],
      "metadata": {
        "id": "nk0kSKtB8p7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login --token X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKAfbM9oLb20",
        "outputId": "4ebe8e68-2474-4d84-f63e-bf5d64704392"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "The token `read` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `read`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"facebook/blt-1b\", trust_remote_code=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "02pEjUvYLIXt",
        "outputId": "14799f05-34f8-4938-dff4-73296f1e6a4e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unrecognized model in facebook/blt-1b. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, aria, aria_text, audio-spectrogram-transformer, autoformer, aya_vision, bamba, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, cohere2, colpali, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dab-detr, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deepseek_v3, deformable_detr, deit, depth_anything, depth_pro, deta, detr, diffllama, dinat, dinov2, dinov2_with_registers, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, emu3, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, gemma3, gemma3_text, git, glm, glm4, glpn, got_ocr2, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, granitemoeshared, granitevision, graphormer, grounding-dino, groupvit, helium, hiera, hubert, ibert, idefics, idefics2, idefics3, idefics3_vision, ijepa, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llama4, llama4_text, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mistral3, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, modernbert, moonshine, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmo2, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, phi4_multimodal, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prompt_depth_anything, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_5_vl, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, qwen3, qwen3_moe, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rt_detr_v2, rwkv, sam, sam_vision_model, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, shieldgemma2, siglip, siglip2, siglip_vision_model, smolvlm, smolvlm_vision, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superglue, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, textnet, time_series_transformer, timesformer, timm_backbone, timm_wrapper, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vitpose, vitpose_backbone, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zamba, zamba2, zoedepth",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-b0751c3eafa9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"facebook/blt-1b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"quantization_config\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             config, kwargs = AutoConfig.from_pretrained(\n\u001b[0m\u001b[1;32m    532\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                 \u001b[0mreturn_unused_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1149\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mCONFIG_MAPPING\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1152\u001b[0m             \u001b[0;34mf\"Unrecognized model in {pretrained_model_name_or_path}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0;34mf\"Should have a `model_type` key in its {CONFIG_NAME}, or contain one of the following strings \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unrecognized model in facebook/blt-1b. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, aria, aria_text, audio-spectrogram-transformer, autoformer, aya_vision, bamba, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, cohere2, colpali, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dab-detr, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deepseek_v3, deformable_detr, deit, depth_anything, depth_pro, deta, detr, diffllama, dinat, dinov2, dinov2_with_registers, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, emu3, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, gemma3, gemma3_text, git, glm, glm4, glpn, got_ocr2, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, granitemoeshared, granitevision, graphormer, grounding-dino, groupvit, helium, hiera, hubert, ibert, idefics, idefics2, idefics3, idefics3_vision, ijepa, imagegpt, informer, instructblip, ..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from huggingface_hub import PyTorchModelHubMixin\n",
        "\n",
        "class ByteLatentTransformer(\n",
        "    nn.Module,\n",
        "    SequenceModelWithOutput,\n",
        "    PyTorchModelHubMixin,\n",
        "    repo_url=\"https://github.com/facebookresearch/blt\",\n",
        "    pipeline_tag=\"text-generation\",\n",
        "    coders={\n",
        "        ByteLatentTransformerArgs: (\n",
        "            lambda x: x.dict(),\n",
        "            lambda data: ByteLatentTransformerArgs.model_validate(**data),\n",
        "        ),\n",
        "    },\n",
        "    license=\"other\"\n",
        "):\n",
        "\n",
        "    def __init__(self, args: ByteLatentTransformerArgs):\n",
        "        (...)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "JRvy2TPHLtpF",
        "outputId": "0e770be6-643a-4f8f-d728-64cb3b859f2b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'SequenceModelWithOutput' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-933bc03daf3c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m class ByteLatentTransformer(\n\u001b[1;32m      5\u001b[0m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mSequenceModelWithOutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mPyTorchModelHubMixin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mrepo_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"https://github.com/facebookresearch/blt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SequenceModelWithOutput' is not defined"
          ]
        }
      ]
    },
    {
      "source": [
        "from torch import nn\n",
        "from huggingface_hub import PyTorchModelHubMixin\n",
        "from bytelatent.model.output import SequenceModelWithOutput # Import the missing class\n",
        "\n",
        "class ByteLatentTransformer(\n",
        "    nn.Module,\n",
        "    SequenceModelWithOutput,\n",
        "    PyTorchModelHubMixin,\n",
        "    repo_url=\"https://github.com/facebookresearch/blt\",\n",
        "    pipeline_tag=\"text-generation\",\n",
        "    coders={\n",
        "        ByteLatentTransformerArgs: (\n",
        "            lambda x: x.dict(),\n",
        "            lambda data: ByteLatentTransformerArgs.model_validate(**data),\n",
        "        ),\n",
        "    },\n",
        "    license=\"other\"\n",
        "):\n",
        "\n",
        "    def __init__(self, args: ByteLatentTransformerArgs):\n",
        "        (...)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "GQPQSWLGL1od",
        "outputId": "ac6b4691-5ef3-48ea-e410-349a1ebd43af"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'bytelatent'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-207059c070dc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhuggingface_hub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPyTorchModelHubMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbytelatent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequenceModelWithOutput\u001b[0m \u001b[0;31m# Import the missing class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m class ByteLatentTransformer(\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bytelatent'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "source": [
        "%cd /content/blt\n",
        "from torch import nn\n",
        "from huggingface_hub import PyTorchModelHubMixin\n",
        "from bytelatent.model.output import SequenceModelWithOutput # Import the missing class\n",
        "\n",
        "class ByteLatentTransformer(\n",
        "    nn.Module,\n",
        "    SequenceModelWithOutput,\n",
        "    PyTorchModelHubMixin,\n",
        "    repo_url=\"https://github.com/facebookresearch/blt\",\n",
        "    pipeline_tag=\"text-generation\",\n",
        "    coders={\n",
        "        ByteLatentTransformerArgs: (\n",
        "            lambda x: x.dict(),\n",
        "            lambda data: ByteLatentTransformerArgs.model_validate(**data),\n",
        "        ),\n",
        "    },\n",
        "    license=\"other\"\n",
        "):\n",
        "\n",
        "    def __init__(self, args: ByteLatentTransformerArgs):\n",
        "        (...)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "goyLnlSeM8t2",
        "outputId": "489ac94a-7683-488f-8858-8238f7c4f3c3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/blt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'bytelatent.model.output'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-77f82da191df>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhuggingface_hub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPyTorchModelHubMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbytelatent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequenceModelWithOutput\u001b[0m \u001b[0;31m# Import the missing class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m class ByteLatentTransformer(\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bytelatent.model.output'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bytelatent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaSr112kLuCl",
        "outputId": "5ba0dd12-6bd2-482c-af3a-d4b8b142b6c3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement bytelatent (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for bytelatent\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "source": [
        "!pip install -e ./blt # Install bytelatent from the cloned repository"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvqqpy34NCy2",
        "outputId": "71afec21-f8f0-4aad-a7ea-b8daa001e399"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/blt\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from bytelatent==0.1.0) (0.2.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from bytelatent==0.1.0) (0.9.0)\n",
            "Collecting xformers (from bytelatent==0.1.0)\n",
            "  Downloading xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->bytelatent==0.1.0) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->bytelatent==0.1.0) (2.32.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xformers->bytelatent==0.1.0) (2.0.2)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from xformers->bytelatent==0.1.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->xformers->bytelatent==0.1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->xformers->bytelatent==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->bytelatent==0.1.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->bytelatent==0.1.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->bytelatent==0.1.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->bytelatent==0.1.0) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->xformers->bytelatent==0.1.0) (3.0.2)\n",
            "Downloading xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl (43.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.4/43.4 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: bytelatent\n",
            "  Building editable for bytelatent (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bytelatent: filename=bytelatent-0.1.0-0.editable-py3-none-any.whl size=8446 sha256=128eb177c41e97728ace5ec69b3a7cfb9d9110a88bbf9d19e26d787c1826b202\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-azmas4th/wheels/10/13/27/f0c4bd462820770c83979f05849abafc28c4fe62dcba1c6585\n",
            "Successfully built bytelatent\n",
            "Installing collected packages: xformers, bytelatent\n",
            "Successfully installed bytelatent-0.1.0 xformers-0.0.29.post3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash /content/blt/dev/lint.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gTlkfliM3xW",
        "outputId": "6475d7bd-aeb6-4228-fb6d-4ee09e6e604d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/blt/dev/lint.sh: line 2: isort: command not found\n",
            "/content/blt/dev/lint.sh: line 3: black: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/blt/bytelatent/eval.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jxg_AIEgNgPN",
        "outputId": "829f8dfe-d0d2-4a91-cab7-25382fcc5eb0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1967, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/integrations/ggml.py\", line 24, in <module>\n",
            "    from tokenizers import Tokenizer, decoders, normalizers, pre_tokenizers, processors\n",
            "ImportError: cannot import name 'Tokenizer' from 'tokenizers' (/content/blt/bytelatent/tokenizers/__init__.py)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/blt/bytelatent/eval.py\", line 11, in <module>\n",
            "    from lm_eval import simple_evaluate\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/lm_eval/__init__.py\", line 4, in <module>\n",
            "    from .evaluator import evaluate, simple_evaluate\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/lm_eval/evaluator.py\", line 12, in <module>\n",
            "    import lm_eval.api.metrics\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/lm_eval/api/metrics.py\", line 12, in <module>\n",
            "    from lm_eval.api.registry import register_aggregation, register_metric\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/lm_eval/api/registry.py\", line 4, in <module>\n",
            "    import evaluate as hf_evaluate\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/evaluate/__init__.py\", line 29, in <module>\n",
            "    from .evaluation_suite import EvaluationSuite\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/evaluate/evaluation_suite/__init__.py\", line 10, in <module>\n",
            "    from ..evaluator import evaluator\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/evaluate/evaluator/__init__.py\", line 17, in <module>\n",
            "    from transformers.pipelines import SUPPORTED_TASKS as SUPPORTED_PIPELINE_TASKS\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/pipelines/__init__.py\", line 23, in <module>\n",
            "    from ..configuration_utils import PretrainedConfig\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py\", line 27, in <module>\n",
            "    from .modeling_gguf_pytorch_utils import load_gguf_checkpoint\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_gguf_pytorch_utils.py\", line 22, in <module>\n",
            "    from .integrations import (\n",
            "  File \"<frozen importlib._bootstrap>\", line 1229, in _handle_fromlist\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1955, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1969, in _get_module\n",
            "    raise RuntimeError(\n",
            "RuntimeError: Failed to import transformers.integrations.ggml because of the following error (look up to see its traceback):\n",
            "cannot import name 'Tokenizer' from 'tokenizers' (/content/blt/bytelatent/tokenizers/__init__.py)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/blt/bytelatent/transformer.py\n"
      ],
      "metadata": {
        "id": "oKDhgRJhN00e"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/blt/bytelatent/print_config.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ue8fhRiqOOcW",
        "outputId": "4f8585f6-1ef9-419a-c7cf-7bb25c229160"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/blt/bytelatent/print_config.py\", line 1, in <module>\n",
            "    from bytelatent.args import TrainArgs\n",
            "  File \"/content/blt/bytelatent/args.py\", line 10, in <module>\n",
            "    from bytelatent.checkpoint import CONSOLIDATE_FOLDER, CheckpointArgs\n",
            "  File \"/content/blt/bytelatent/checkpoint.py\", line 26, in <module>\n",
            "    from bytelatent.distributed import get_is_master\n",
            "  File \"/content/blt/bytelatent/distributed.py\", line 54, in <module>\n",
            "    torch.ops.xformers.efficient_attention_forward_cutlass.default\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_ops.py\", line 1232, in __getattr__\n",
            "    raise AttributeError(\n",
            "AttributeError: '_OpNamespace' 'xformers' object has no attribute 'efficient_attention_forward_cutlass'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPGasP6xOW-d",
        "outputId": "f57f3cc1-58be-42a0-eb72-7845e0b0d628"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                               Version             Editable project location\n",
            "------------------------------------- ------------------- -------------------------\n",
            "absl-py                               1.4.0\n",
            "accelerate                            1.5.2\n",
            "adlfs                                 2024.12.0\n",
            "aiobotocore                           2.21.1\n",
            "aiohappyeyeballs                      2.6.1\n",
            "aiohttp                               3.11.15\n",
            "aioitertools                          0.12.0\n",
            "aiosignal                             1.3.2\n",
            "alabaster                             1.0.0\n",
            "albucore                              0.0.23\n",
            "albumentations                        2.0.5\n",
            "ale-py                                0.10.2\n",
            "altair                                5.5.0\n",
            "annotated-types                       0.7.0\n",
            "antlr4-python3-runtime                4.9.3\n",
            "anyio                                 4.9.0\n",
            "argon2-cffi                           23.1.0\n",
            "argon2-cffi-bindings                  21.2.0\n",
            "array_record                          0.7.1\n",
            "arviz                                 0.21.0\n",
            "astropy                               7.0.1\n",
            "astropy-iers-data                     0.2025.4.14.0.37.22\n",
            "astunparse                            1.6.3\n",
            "atpublic                              5.1\n",
            "attrs                                 25.3.0\n",
            "audioread                             3.0.1\n",
            "autograd                              1.7.0\n",
            "azure-core                            1.33.0\n",
            "azure-datalake-store                  0.0.53\n",
            "azure-identity                        1.21.0\n",
            "azure-storage-blob                    12.25.1\n",
            "babel                                 2.17.0\n",
            "backcall                              0.2.0\n",
            "backports.tarfile                     1.2.0\n",
            "bcrypt                                4.3.0\n",
            "beautifulsoup4                        4.13.4\n",
            "betterproto                           2.0.0b6\n",
            "bigframes                             1.42.0\n",
            "bigquery-magics                       0.9.0\n",
            "bleach                                6.2.0\n",
            "blinker                               1.9.0\n",
            "blis                                  1.3.0\n",
            "blobfile                              3.0.0\n",
            "blosc2                                3.3.0\n",
            "bokeh                                 3.6.3\n",
            "botocore                              1.37.1\n",
            "Bottleneck                            1.4.2\n",
            "bqplot                                0.12.44\n",
            "branca                                0.8.1\n",
            "bytelatent                            0.1.0               /content/blt\n",
            "CacheControl                          0.14.2\n",
            "cachetools                            5.5.2\n",
            "catalogue                             2.0.10\n",
            "certifi                               2025.1.31\n",
            "cffi                                  1.17.1\n",
            "chardet                               5.2.0\n",
            "charset-normalizer                    3.4.1\n",
            "chex                                  0.1.89\n",
            "circuitbreaker                        2.1.3\n",
            "clarabel                              0.10.0\n",
            "click                                 8.1.8\n",
            "cloudpathlib                          0.21.0\n",
            "cloudpickle                           3.1.1\n",
            "cmake                                 3.31.6\n",
            "cmdstanpy                             1.2.5\n",
            "colorama                              0.4.6\n",
            "colorcet                              3.1.0\n",
            "colorlover                            0.3.0\n",
            "colour                                0.1.5\n",
            "community                             1.0.0b1\n",
            "confection                            0.1.5\n",
            "cons                                  0.4.6\n",
            "contourpy                             1.3.2\n",
            "cramjam                               2.10.0\n",
            "cryptography                          43.0.3\n",
            "cuda-python                           12.6.2.post1\n",
            "cudf-cu12                             25.2.1\n",
            "cudf-polars-cu12                      25.2.2\n",
            "cufflinks                             0.17.3\n",
            "cuml-cu12                             25.2.1\n",
            "cupy-cuda12x                          13.3.0\n",
            "cuvs-cu12                             25.2.1\n",
            "cvxopt                                1.3.2\n",
            "cvxpy                                 1.6.5\n",
            "cycler                                0.12.1\n",
            "cyipopt                               1.5.0\n",
            "cymem                                 2.0.11\n",
            "Cython                                3.0.12\n",
            "dask                                  2024.12.1\n",
            "dask-cuda                             25.2.0\n",
            "dask-cudf-cu12                        25.2.2\n",
            "dask-expr                             1.1.21\n",
            "DataProperty                          1.1.0\n",
            "datascience                           0.17.6\n",
            "datasets                              3.5.0\n",
            "datatrove                             0.4.0\n",
            "db-dtypes                             1.4.2\n",
            "dbus-python                           1.2.18\n",
            "debugpy                               1.8.0\n",
            "decorator                             4.4.2\n",
            "defusedxml                            0.7.1\n",
            "Deprecated                            1.2.18\n",
            "diffusers                             0.32.2\n",
            "dill                                  0.3.8\n",
            "distributed                           2024.12.1\n",
            "distributed-ucxx-cu12                 0.42.0\n",
            "distro                                1.9.0\n",
            "dlib                                  19.24.6\n",
            "dm-tree                               0.1.9\n",
            "docker-pycreds                        0.4.0\n",
            "docstring_parser                      0.16\n",
            "docutils                              0.21.2\n",
            "dopamine_rl                           4.1.2\n",
            "dropbox                               12.0.2\n",
            "dropboxdrivefs                        1.4.1\n",
            "duckdb                                1.2.2\n",
            "earthengine-api                       1.5.11\n",
            "easydict                              1.13\n",
            "editdistance                          0.8.1\n",
            "eerepr                                0.1.1\n",
            "einops                                0.8.1\n",
            "en_core_web_sm                        3.8.0\n",
            "entrypoints                           0.4\n",
            "et_xmlfile                            2.0.0\n",
            "etils                                 1.12.2\n",
            "etuples                               0.3.9\n",
            "evaluate                              0.4.3\n",
            "Farama-Notifications                  0.0.4\n",
            "fastai                                2.7.19\n",
            "fastcore                              1.7.29\n",
            "fastdownload                          0.0.7\n",
            "fastjsonschema                        2.21.1\n",
            "fastprogress                          1.0.3\n",
            "fastrlock                             0.8.3\n",
            "filelock                              3.18.0\n",
            "firebase-admin                        6.7.0\n",
            "Flask                                 3.1.0\n",
            "flatbuffers                           25.2.10\n",
            "flax                                  0.10.5\n",
            "folium                                0.19.5\n",
            "fonttools                             4.57.0\n",
            "frozendict                            2.4.6\n",
            "frozenlist                            1.5.0\n",
            "fsspec                                2024.12.0\n",
            "fusepy                                3.0.1\n",
            "future                                1.0.0\n",
            "gast                                  0.6.0\n",
            "gcsfs                                 2024.12.0\n",
            "GDAL                                  3.6.4\n",
            "gdown                                 5.2.0\n",
            "geemap                                0.35.3\n",
            "geocoder                              1.38.1\n",
            "geographiclib                         2.0\n",
            "geopandas                             1.0.1\n",
            "geopy                                 2.4.1\n",
            "gin-config                            0.5.0\n",
            "gitdb                                 4.0.12\n",
            "GitPython                             3.1.44\n",
            "glob2                                 0.7\n",
            "google                                2.0.3\n",
            "google-ai-generativelanguage          0.6.15\n",
            "google-api-core                       2.24.2\n",
            "google-api-python-client              2.164.0\n",
            "google-auth                           2.38.0\n",
            "google-auth-httplib2                  0.2.0\n",
            "google-auth-oauthlib                  1.2.1\n",
            "google-cloud-aiplatform               1.88.0\n",
            "google-cloud-bigquery                 3.31.0\n",
            "google-cloud-bigquery-connection      1.18.2\n",
            "google-cloud-bigquery-storage         2.30.0\n",
            "google-cloud-bigtable                 2.30.0\n",
            "google-cloud-core                     2.4.3\n",
            "google-cloud-dataproc                 5.18.1\n",
            "google-cloud-datastore                2.21.0\n",
            "google-cloud-firestore                2.20.1\n",
            "google-cloud-functions                1.20.3\n",
            "google-cloud-iam                      2.19.0\n",
            "google-cloud-language                 2.17.1\n",
            "google-cloud-pubsub                   2.29.0\n",
            "google-cloud-resource-manager         1.14.2\n",
            "google-cloud-spanner                  3.53.0\n",
            "google-cloud-storage                  2.19.0\n",
            "google-cloud-translate                3.20.2\n",
            "google-colab                          1.0.0\n",
            "google-crc32c                         1.7.1\n",
            "google-genai                          1.10.0\n",
            "google-generativeai                   0.8.4\n",
            "google-pasta                          0.2.0\n",
            "google-resumable-media                2.7.2\n",
            "google-spark-connect                  0.5.2\n",
            "googleapis-common-protos              1.70.0\n",
            "googledrivedownloader                 1.1.0\n",
            "graphviz                              0.20.3\n",
            "greenlet                              3.2.0\n",
            "grpc-google-iam-v1                    0.14.2\n",
            "grpc-interceptor                      0.15.4\n",
            "grpcio                                1.71.0\n",
            "grpcio-status                         1.71.0\n",
            "grpclib                               0.4.7\n",
            "gspread                               6.2.0\n",
            "gspread-dataframe                     4.0.0\n",
            "gym                                   0.25.2\n",
            "gym-notices                           0.0.8\n",
            "gymnasium                             1.1.1\n",
            "h11                                   0.14.0\n",
            "h2                                    4.2.0\n",
            "h5netcdf                              1.6.1\n",
            "h5py                                  3.13.0\n",
            "hdbscan                               0.8.40\n",
            "highspy                               1.9.0\n",
            "holidays                              0.70\n",
            "holoviews                             1.20.2\n",
            "hpack                                 4.1.0\n",
            "html5lib                              1.1\n",
            "httpcore                              1.0.8\n",
            "httpimport                            1.4.1\n",
            "httplib2                              0.22.0\n",
            "httpx                                 0.28.1\n",
            "huggingface-hub                       0.30.2\n",
            "humanize                              4.12.2\n",
            "hyperframe                            6.1.0\n",
            "hyperopt                              0.2.7\n",
            "ibis-framework                        9.5.0\n",
            "idna                                  3.10\n",
            "imageio                               2.37.0\n",
            "imageio-ffmpeg                        0.6.0\n",
            "imagesize                             1.4.1\n",
            "imbalanced-learn                      0.13.0\n",
            "immutabledict                         4.2.1\n",
            "importlib_metadata                    8.6.1\n",
            "importlib_resources                   6.5.2\n",
            "imutils                               0.5.4\n",
            "inflect                               7.5.0\n",
            "iniconfig                             2.1.0\n",
            "intel-cmplr-lib-ur                    2025.1.0\n",
            "intel-openmp                          2025.1.0\n",
            "ipyevents                             2.0.2\n",
            "ipyfilechooser                        0.6.0\n",
            "ipykernel                             6.17.1\n",
            "ipyleaflet                            0.19.2\n",
            "ipyparallel                           8.8.0\n",
            "ipython                               7.34.0\n",
            "ipython-genutils                      0.2.0\n",
            "ipython-sql                           0.5.0\n",
            "ipytree                               0.2.2\n",
            "ipywidgets                            7.7.1\n",
            "isodate                               0.7.2\n",
            "itsdangerous                          2.2.0\n",
            "jaraco.classes                        3.4.0\n",
            "jaraco.context                        6.0.1\n",
            "jaraco.functools                      4.1.0\n",
            "jax                                   0.5.2\n",
            "jax-cuda12-pjrt                       0.5.1\n",
            "jax-cuda12-plugin                     0.5.1\n",
            "jaxlib                                0.5.1\n",
            "jeepney                               0.9.0\n",
            "jellyfish                             1.1.0\n",
            "jieba                                 0.42.1\n",
            "Jinja2                                3.1.6\n",
            "jiter                                 0.9.0\n",
            "jmespath                              1.0.1\n",
            "joblib                                1.4.2\n",
            "jsonlines                             4.0.0\n",
            "jsonpatch                             1.33\n",
            "jsonpickle                            4.0.5\n",
            "jsonpointer                           3.0.0\n",
            "jsonschema                            4.23.0\n",
            "jsonschema-specifications             2024.10.1\n",
            "jupyter-client                        6.1.12\n",
            "jupyter-console                       6.1.0\n",
            "jupyter_core                          5.7.2\n",
            "jupyter-leaflet                       0.19.2\n",
            "jupyter-server                        1.16.0\n",
            "jupyterlab_pygments                   0.3.0\n",
            "jupyterlab_widgets                    3.0.14\n",
            "kaggle                                1.7.4.2\n",
            "kagglehub                             0.3.11\n",
            "keras                                 3.8.0\n",
            "keras-hub                             0.18.1\n",
            "keras-nlp                             0.18.1\n",
            "keyring                               25.6.0\n",
            "keyrings.google-artifactregistry-auth 1.1.2\n",
            "kiwisolver                            1.4.8\n",
            "langchain                             0.3.23\n",
            "langchain-core                        0.3.52\n",
            "langchain-text-splitters              0.3.8\n",
            "langcodes                             3.5.0\n",
            "langsmith                             0.3.31\n",
            "language_data                         1.3.0\n",
            "launchpadlib                          1.10.16\n",
            "lazr.restfulclient                    0.14.4\n",
            "lazr.uri                              1.0.6\n",
            "lazy_loader                           0.4\n",
            "libarchive-c                          5.2\n",
            "libclang                              18.1.1\n",
            "libcudf-cu12                          25.2.1\n",
            "libcugraph-cu12                       25.2.0\n",
            "libcuml-cu12                          25.2.1\n",
            "libcuvs-cu12                          25.2.1\n",
            "libkvikio-cu12                        25.2.1\n",
            "libraft-cu12                          25.2.0\n",
            "librosa                               0.11.0\n",
            "libucx-cu12                           1.18.0\n",
            "libucxx-cu12                          0.42.0\n",
            "lightgbm                              4.5.0\n",
            "linkify-it-py                         2.0.3\n",
            "llvmlite                              0.43.0\n",
            "lm_eval                               0.4.8\n",
            "locket                                1.0.0\n",
            "lockfile                              0.12.2\n",
            "logical-unification                   0.4.6\n",
            "loguru                                0.7.3\n",
            "luigi                                 3.6.0\n",
            "lxml                                  5.3.2\n",
            "Mako                                  1.1.3\n",
            "marisa-trie                           1.2.1\n",
            "Markdown                              3.8\n",
            "markdown-it-py                        3.0.0\n",
            "MarkupSafe                            3.0.2\n",
            "matplotlib                            3.10.0\n",
            "matplotlib-inline                     0.1.7\n",
            "matplotlib-venn                       1.1.2\n",
            "mbstrdecoder                          1.1.4\n",
            "mdit-py-plugins                       0.4.2\n",
            "mdurl                                 0.1.2\n",
            "miniKanren                            1.0.3\n",
            "missingno                             0.5.2\n",
            "mistune                               3.1.3\n",
            "mizani                                0.13.3\n",
            "mkl                                   2025.0.1\n",
            "ml-dtypes                             0.4.1\n",
            "mlxtend                               0.23.4\n",
            "more-itertools                        10.6.0\n",
            "moviepy                               1.0.3\n",
            "mpmath                                1.3.0\n",
            "msal                                  1.32.0\n",
            "msal-extensions                       1.3.1\n",
            "msgpack                               1.1.0\n",
            "msgspec                               0.19.0\n",
            "multidict                             6.4.3\n",
            "multipledispatch                      1.0.0\n",
            "multiprocess                          0.70.16\n",
            "multitasking                          0.0.11\n",
            "murmurhash                            1.0.12\n",
            "music21                               9.3.0\n",
            "namex                                 0.0.8\n",
            "narwhals                              1.35.0\n",
            "natsort                               8.4.0\n",
            "nbclassic                             1.2.0\n",
            "nbclient                              0.10.2\n",
            "nbconvert                             7.16.6\n",
            "nbformat                              5.10.4\n",
            "ndindex                               1.9.2\n",
            "nest-asyncio                          1.6.0\n",
            "networkx                              3.4.2\n",
            "nibabel                               5.3.2\n",
            "nltk                                  3.9.1\n",
            "notebook                              6.5.7\n",
            "notebook_shim                         0.2.4\n",
            "numba                                 0.60.0\n",
            "numba-cuda                            0.2.0\n",
            "numexpr                               2.10.2\n",
            "numpy                                 2.0.2\n",
            "nvidia-cublas-cu12                    12.4.5.8\n",
            "nvidia-cuda-cupti-cu12                12.4.127\n",
            "nvidia-cuda-nvcc-cu12                 12.5.82\n",
            "nvidia-cuda-nvrtc-cu12                12.4.127\n",
            "nvidia-cuda-runtime-cu12              12.4.127\n",
            "nvidia-cudnn-cu12                     9.1.0.70\n",
            "nvidia-cufft-cu12                     11.2.1.3\n",
            "nvidia-curand-cu12                    10.3.5.147\n",
            "nvidia-cusolver-cu12                  11.6.1.9\n",
            "nvidia-cusparse-cu12                  12.3.1.170\n",
            "nvidia-cusparselt-cu12                0.6.2\n",
            "nvidia-ml-py                          12.570.86\n",
            "nvidia-nccl-cu12                      2.21.5\n",
            "nvidia-nvcomp-cu12                    4.2.0.11\n",
            "nvidia-nvjitlink-cu12                 12.4.127\n",
            "nvidia-nvtx-cu12                      12.4.127\n",
            "nvtx                                  0.2.11\n",
            "nx-cugraph-cu12                       25.2.0\n",
            "oauth2client                          4.1.3\n",
            "oauthlib                              3.2.2\n",
            "objprint                              0.3.0\n",
            "oci                                   2.150.2\n",
            "ocifs                                 1.3.2\n",
            "omegaconf                             2.3.0\n",
            "openai                                1.75.0\n",
            "opencv-contrib-python                 4.11.0.86\n",
            "opencv-python                         4.11.0.86\n",
            "opencv-python-headless                4.11.0.86\n",
            "openpyxl                              3.1.5\n",
            "opentelemetry-api                     1.32.1\n",
            "opentelemetry-sdk                     1.32.1\n",
            "opentelemetry-semantic-conventions    0.53b1\n",
            "opt_einsum                            3.4.0\n",
            "optax                                 0.2.4\n",
            "optree                                0.15.0\n",
            "orbax-checkpoint                      0.11.12\n",
            "orjson                                3.10.16\n",
            "osqp                                  1.0.3\n",
            "packaging                             24.2\n",
            "pandas                                2.2.2\n",
            "pandas-datareader                     0.10.0\n",
            "pandas-gbq                            0.28.0\n",
            "pandas-stubs                          2.2.2.240909\n",
            "pandocfilters                         1.5.1\n",
            "panel                                 1.6.2\n",
            "param                                 2.2.0\n",
            "paramiko                              3.5.1\n",
            "parso                                 0.8.4\n",
            "parsy                                 2.1\n",
            "partd                                 1.4.2\n",
            "pathlib                               1.0.1\n",
            "pathvalidate                          3.2.3\n",
            "patsy                                 1.0.1\n",
            "peewee                                3.17.9\n",
            "peft                                  0.14.0\n",
            "pexpect                               4.9.0\n",
            "pickleshare                           0.7.5\n",
            "pillow                                11.1.0\n",
            "pip                                   24.1.2\n",
            "platformdirs                          4.3.7\n",
            "plotly                                5.24.1\n",
            "plotnine                              0.14.5\n",
            "pluggy                                1.5.0\n",
            "ply                                   3.11\n",
            "polars                                1.21.0\n",
            "pooch                                 1.8.2\n",
            "portalocker                           3.1.1\n",
            "portpicker                            1.5.2\n",
            "preshed                               3.0.9\n",
            "prettytable                           3.16.0\n",
            "proglog                               0.1.11\n",
            "progressbar2                          4.5.0\n",
            "prometheus_client                     0.21.1\n",
            "promise                               2.3\n",
            "prompt_toolkit                        3.0.51\n",
            "propcache                             0.3.1\n",
            "prophet                               1.1.6\n",
            "proto-plus                            1.26.1\n",
            "protobuf                              5.29.4\n",
            "psutil                                5.9.5\n",
            "psycopg2                              2.9.10\n",
            "ptyprocess                            0.7.0\n",
            "py-cpuinfo                            9.0.0\n",
            "py4j                                  0.10.9.7\n",
            "pyarrow                               18.1.0\n",
            "pyasn1                                0.6.1\n",
            "pyasn1_modules                        0.4.2\n",
            "pybind11                              2.13.6\n",
            "pycairo                               1.28.0\n",
            "pycocotools                           2.0.8\n",
            "pycparser                             2.22\n",
            "pycryptodomex                         3.22.0\n",
            "pydantic                              2.11.3\n",
            "pydantic_core                         2.33.1\n",
            "pydata-google-auth                    1.9.1\n",
            "pydot                                 3.0.4\n",
            "pydotplus                             2.0.2\n",
            "PyDrive                               1.3.1\n",
            "PyDrive2                              1.21.3\n",
            "pyerfa                                2.0.1.5\n",
            "pygame                                2.6.1\n",
            "pygit2                                1.17.0\n",
            "Pygments                              2.18.0\n",
            "PyGObject                             3.42.0\n",
            "PyJWT                                 2.10.1\n",
            "pylibcudf-cu12                        25.2.1\n",
            "pylibcugraph-cu12                     25.2.0\n",
            "pylibraft-cu12                        25.2.0\n",
            "pymc                                  5.21.2\n",
            "pymystem3                             0.2.0\n",
            "PyNaCl                                1.5.0\n",
            "pynndescent                           0.5.13\n",
            "pynvjitlink-cu12                      0.5.2\n",
            "pynvml                                12.0.0\n",
            "pyogrio                               0.10.0\n",
            "Pyomo                                 6.8.2\n",
            "PyOpenGL                              3.1.9\n",
            "pyOpenSSL                             24.2.1\n",
            "pyparsing                             3.2.3\n",
            "pyperclip                             1.9.0\n",
            "pyproj                                3.7.1\n",
            "pyshp                                 2.3.1\n",
            "PySocks                               1.7.1\n",
            "pyspark                               3.5.5\n",
            "pyspnego                              0.11.2\n",
            "pytablewriter                         1.2.1\n",
            "pytensor                              2.30.3\n",
            "pytest                                8.3.5\n",
            "python-apt                            0.0.0\n",
            "python-box                            7.3.2\n",
            "python-daemon                         3.1.2\n",
            "python-dateutil                       2.8.2\n",
            "python-louvain                        0.16\n",
            "python-slugify                        8.0.4\n",
            "python-snappy                         0.7.3\n",
            "python-utils                          3.9.1\n",
            "pytz                                  2025.2\n",
            "pyviz_comms                           3.0.4\n",
            "PyYAML                                6.0.2\n",
            "pyzmq                                 24.0.1\n",
            "raft-dask-cu12                        25.2.0\n",
            "rapids-dask-dependency                25.2.0\n",
            "ratelim                               0.1.6\n",
            "referencing                           0.36.2\n",
            "regex                                 2024.11.6\n",
            "requests                              2.32.3\n",
            "requests-oauthlib                     2.0.0\n",
            "requests-toolbelt                     1.0.0\n",
            "requirements-parser                   0.9.0\n",
            "rich                                  13.9.4\n",
            "rmm-cu12                              25.2.0\n",
            "roman-numerals-py                     3.1.0\n",
            "rouge_score                           0.1.2\n",
            "rpds-py                               0.24.0\n",
            "rpy2                                  3.5.17\n",
            "rsa                                   4.9.1\n",
            "s3fs                                  2024.12.0\n",
            "sacrebleu                             2.5.1\n",
            "safetensors                           0.5.3\n",
            "scikit-image                          0.25.2\n",
            "scikit-learn                          1.6.1\n",
            "scipy                                 1.14.1\n",
            "scooby                                0.10.0\n",
            "scs                                   3.2.7.post2\n",
            "seaborn                               0.13.2\n",
            "SecretStorage                         3.3.3\n",
            "Send2Trash                            1.8.3\n",
            "sentence-transformers                 3.4.1\n",
            "sentencepiece                         0.2.0\n",
            "sentry-sdk                            2.26.1\n",
            "setproctitle                          1.3.5\n",
            "setuptools                            75.2.0\n",
            "shap                                  0.47.1\n",
            "shapely                               2.1.0\n",
            "shellingham                           1.5.4\n",
            "simple-parsing                        0.1.7\n",
            "simplejson                            3.20.1\n",
            "simsimd                               6.2.1\n",
            "six                                   1.17.0\n",
            "sklearn-compat                        0.1.3\n",
            "sklearn-pandas                        2.2.0\n",
            "slicer                                0.0.8\n",
            "smart-open                            7.1.0\n",
            "smbprotocol                           1.15.0\n",
            "smmap                                 5.0.2\n",
            "sniffio                               1.3.1\n",
            "snowballstemmer                       2.2.0\n",
            "sortedcontainers                      2.4.0\n",
            "soundfile                             0.13.1\n",
            "soupsieve                             2.6\n",
            "soxr                                  0.5.0.post1\n",
            "spacy                                 3.8.5\n",
            "spacy-legacy                          3.0.12\n",
            "spacy-loggers                         1.0.5\n",
            "spanner-graph-notebook                1.1.6\n",
            "Sphinx                                8.2.3\n",
            "sphinxcontrib-applehelp               2.0.0\n",
            "sphinxcontrib-devhelp                 2.0.0\n",
            "sphinxcontrib-htmlhelp                2.1.0\n",
            "sphinxcontrib-jsmath                  1.0.1\n",
            "sphinxcontrib-qthelp                  2.0.0\n",
            "sphinxcontrib-serializinghtml         2.0.0\n",
            "SQLAlchemy                            2.0.40\n",
            "sqlglot                               25.20.2\n",
            "sqlitedict                            2.1.0\n",
            "sqlparse                              0.5.3\n",
            "srsly                                 2.5.1\n",
            "stanio                                0.5.1\n",
            "statsmodels                           0.14.4\n",
            "stone                                 3.3.1\n",
            "stringzilla                           3.12.4\n",
            "submitit                              1.5.2\n",
            "sympy                                 1.13.1\n",
            "tabledata                             1.3.4\n",
            "tables                                3.10.2\n",
            "tabulate                              0.9.0\n",
            "tbb                                   2022.1.0\n",
            "tblib                                 3.1.0\n",
            "tcmlib                                1.3.0\n",
            "tcolorpy                              0.1.7\n",
            "tenacity                              8.5.0\n",
            "tensorboard                           2.18.0\n",
            "tensorboard-data-server               0.7.2\n",
            "tensorflow                            2.18.0\n",
            "tensorflow-datasets                   4.9.8\n",
            "tensorflow_decision_forests           1.11.0\n",
            "tensorflow-hub                        0.16.1\n",
            "tensorflow-io-gcs-filesystem          0.37.1\n",
            "tensorflow-metadata                   1.17.1\n",
            "tensorflow-probability                0.25.0\n",
            "tensorflow-text                       2.18.1\n",
            "tensorstore                           0.1.73\n",
            "termcolor                             3.0.1\n",
            "terminado                             0.18.1\n",
            "text-unidecode                        1.3\n",
            "textblob                              0.19.0\n",
            "tf_keras                              2.18.0\n",
            "tf-slim                               1.1.0\n",
            "thinc                                 8.3.6\n",
            "threadpoolctl                         3.6.0\n",
            "tifffile                              2025.3.30\n",
            "tiktoken                              0.9.0\n",
            "timm                                  1.0.15\n",
            "tinycss2                              1.4.0\n",
            "tokenizers                            0.21.1\n",
            "toml                                  0.10.2\n",
            "toolz                                 0.12.1\n",
            "torch                                 2.6.0+cu124\n",
            "torchaudio                            2.6.0+cu124\n",
            "torchsummary                          1.5.1\n",
            "torchvision                           0.21.0+cu124\n",
            "tornado                               6.4.2\n",
            "tqdm                                  4.67.1\n",
            "tqdm-multiprocess                     0.0.11\n",
            "traitlets                             5.7.1\n",
            "traittypes                            0.2.1\n",
            "transformers                          4.51.3\n",
            "treelite                              4.4.1\n",
            "treescope                             0.1.9\n",
            "triton                                3.2.0\n",
            "tweepy                                4.15.0\n",
            "typeguard                             4.4.2\n",
            "typepy                                1.3.4\n",
            "typer                                 0.15.2\n",
            "types-pytz                            2025.2.0.20250326\n",
            "types-setuptools                      78.1.0.20250329\n",
            "typing_extensions                     4.13.2\n",
            "typing-inspection                     0.4.0\n",
            "tzdata                                2025.2\n",
            "tzlocal                               5.3.1\n",
            "uc-micro-py                           1.0.3\n",
            "ucx-py-cu12                           0.42.0\n",
            "ucxx-cu12                             0.42.0\n",
            "umap-learn                            0.5.7\n",
            "umf                                   0.10.0\n",
            "uritemplate                           4.1.1\n",
            "urllib3                               2.3.0\n",
            "vega-datasets                         0.9.0\n",
            "viztracer                             1.0.3\n",
            "wadllib                               1.3.6\n",
            "wandb                                 0.19.9\n",
            "wasabi                                1.1.3\n",
            "wcwidth                               0.2.13\n",
            "weasel                                0.4.1\n",
            "webcolors                             24.11.1\n",
            "webencodings                          0.5.1\n",
            "websocket-client                      1.8.0\n",
            "websockets                            15.0.1\n",
            "Werkzeug                              3.1.3\n",
            "wheel                                 0.45.1\n",
            "widgetsnbextension                    3.6.10\n",
            "word2number                           1.1\n",
            "wordcloud                             1.9.4\n",
            "wrapt                                 1.17.2\n",
            "wurlitzer                             3.1.1\n",
            "xarray                                2025.1.2\n",
            "xarray-einstats                       0.8.0\n",
            "xformers                              0.0.29.post3\n",
            "xgboost                               2.1.4\n",
            "xlrd                                  2.0.1\n",
            "xxhash                                3.5.0\n",
            "xyzservices                           2025.1.0\n",
            "yarl                                  1.19.0\n",
            "ydf                                   0.11.0\n",
            "yellowbrick                           1.5\n",
            "yfinance                              0.2.55\n",
            "zict                                  3.0.0\n",
            "zipp                                  3.21.0\n",
            "zstandard                             0.23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/blt/bytelatent/test_config_parser.py"
      ],
      "metadata": {
        "id": "YK-bWVbROqLh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/blt/bytelatent/test_entropy_model.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0SOiT-rOZfm",
        "outputId": "4f7b9093-e7fd-40d5-b5d2-e5a4033a6afb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/blt/bytelatent/test_entropy_model.py\", line 7, in <module>\n",
            "    from bytelatent.data.iterators.arrow_iterator import ArrowFileIteratorState\n",
            "  File \"/content/blt/bytelatent/data/iterators/arrow_iterator.py\", line 22, in <module>\n",
            "    from bytelatent.preprocess.preprocess_entropies import get_id_key, get_text\n",
            "  File \"/content/blt/bytelatent/preprocess/preprocess_entropies.py\", line 13, in <module>\n",
            "    from bytelatent.data.patcher import calculate_entropies\n",
            "  File \"/content/blt/bytelatent/data/patcher.py\", line 13, in <module>\n",
            "    from bytelatent.distributed import get_local_rank\n",
            "  File \"/content/blt/bytelatent/distributed.py\", line 54, in <module>\n",
            "    torch.ops.xformers.efficient_attention_forward_cutlass.default\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_ops.py\", line 1232, in __getattr__\n",
            "    raise AttributeError(\n",
            "AttributeError: '_OpNamespace' 'xformers' object has no attribute 'efficient_attention_forward_cutlass'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
        "\n",
        "import json\n",
        "import logging\n",
        "import math\n",
        "import os\n",
        "from collections import defaultdict\n",
        "from datetime import datetime\n",
        "\n",
        "import torch\n",
        "from lm_eval import simple_evaluate\n",
        "from lm_eval.api.instance import Instance\n",
        "from lm_eval.api.model import LM\n",
        "from rich.progress import track\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from bytelatent.args import (\n",
        "    EvalArgs,\n",
        "    TrainArgs,\n",
        "    ValidationArgs,\n",
        "    find_and_sanitize_chunks,\n",
        ")\n",
        "from bytelatent.checkpoint import CONSOLIDATE_FOLDER, consolidate_checkpoints\n",
        "from bytelatent.config_parser import parse_args_to_pydantic_model\n",
        "from bytelatent.data.file_util import get_fs\n",
        "from bytelatent.data.iterators.arrow_iterator import ArrowFileIterator\n",
        "from bytelatent.data.iterators.limit_iterator import LimitIterator\n",
        "from bytelatent.data.iterators.packing_iterator import (\n",
        "    PackingArgs,\n",
        "    PackingIterator,\n",
        "    PackingMode,\n",
        ")\n",
        "from bytelatent.data.iterators.preprocess_iterator import PreprocessIterator\n",
        "from bytelatent.data.iterators.sequence_iterator import (\n",
        "    SequenceIterator,\n",
        "    SequencePackingArgs,\n",
        ")\n",
        "from bytelatent.data.patcher import PatcherArgs, PatchingModeEnum\n",
        "from bytelatent.distributed import (\n",
        "    DistributedArgs,\n",
        "    dist_mean_dict,\n",
        "    dist_sum,\n",
        "    get_device_mesh,\n",
        "    get_global_rank,\n",
        "    get_world_size,\n",
        "    setup_torch_distributed,\n",
        "    to_py_num,\n",
        ")\n",
        "from bytelatent.generate import (\n",
        "    PackedCausalTransformerGenerator,\n",
        "    load_consolidated_model_and_tokenizer,\n",
        ")\n",
        "from bytelatent.model.blt import ByteLatentTransformer\n",
        "from bytelatent.tokenizers.build_tokenizer import TokenizerArgs\n",
        "from bytelatent.transformer import LMTransformer\n",
        "\n",
        "EVAL_FOLDER_NAME = \"{:010d}\"\n",
        "\n",
        "logger = logging.getLogger()\n",
        "\n",
        "\n",
        "def all_dicts_same(dict_list):\n",
        "    if not dict_list:  # Check if the list is empty\n",
        "        return True\n",
        "\n",
        "    # Compare each dictionary to the first one\n",
        "    first_dict = dict_list[0]\n",
        "    return all(d == first_dict for d in dict_list)\n",
        "\n",
        "\n",
        "class MockAccelerator:\n",
        "    def gather(self, tensor):\n",
        "        l = [torch.zeros_like(tensor) for _ in range(get_world_size())]\n",
        "        torch.distributed.all_gather(l, tensor)\n",
        "        return torch.stack(l)\n",
        "\n",
        "    def wait_for_everyone(self):\n",
        "        torch.distributed.barrier()\n",
        "\n",
        "\n",
        "# Light wrapper around generator for lm-eval harness\n",
        "class EvalHarnessLM(LM):\n",
        "    def __init__(self, generator):\n",
        "        super().__init__()\n",
        "        self.generator = generator\n",
        "        self.accelerator = MockAccelerator()\n",
        "        self._rank = get_global_rank()\n",
        "        self._world_size = get_world_size()\n",
        "        self.device = generator.device\n",
        "\n",
        "    def generate_until(self, requests: list[Instance]) -> list[str]:\n",
        "        prompts, gen_args = zip(*[req.args for req in requests])\n",
        "        assert all_dicts_same(gen_args), \"Doesn't support different gen args for now\"\n",
        "        gen_args = gen_args[0]\n",
        "        temperature = gen_args.get(\"temperature\", 0.0)\n",
        "        top_p = gen_args.get(\"top_p\", None)\n",
        "        top_k = gen_args.get(\"top_k\", None)\n",
        "        until = gen_args.get(\"until\", [])\n",
        "\n",
        "        self.generator.temperature = temperature\n",
        "        self.generator.top_p = top_p\n",
        "        self.generator.top_k = top_k\n",
        "        self.generator.until = until\n",
        "        generations, _, _ = self.generator.generate(prompts)\n",
        "        filtered_gen = []\n",
        "        for g in generations:\n",
        "            for e in until:\n",
        "                g = g.replace(e, \"\")\n",
        "            filtered_gen.append(g)\n",
        "        return filtered_gen\n",
        "\n",
        "    def loglikelihood(self, requests: list[Instance]) -> list[tuple[float, bool]]:\n",
        "        prompts, continuations = zip(*[req.args for req in requests])\n",
        "        inputs = [req.args[0] + req.args[1] for req in requests]\n",
        "        max_gen_len = self.generator.max_gen_len\n",
        "        # We temporarily lower max gen len\n",
        "        self.generator.max_gen_len = 1\n",
        "        _, lls, greedy = self.generator.generate(inputs)\n",
        "        results = []\n",
        "        for p, ll, gr in zip(prompts, lls, greedy):\n",
        "            p_len = len(\n",
        "                self.generator.tokenizer.encode(p, add_bos=False, add_eos=False)\n",
        "            )\n",
        "            results.append((ll[p_len:].sum().item(), gr[p_len:].all().item()))\n",
        "\n",
        "        self.generator.max_gen_len = max_gen_len\n",
        "        return results\n",
        "\n",
        "    def loglikelihood_rolling(self, requests: list[Instance]) -> list[float]:\n",
        "        prompts = [req.args[0] for req in requests]\n",
        "        max_gen_len = self.generator.max_gen_len\n",
        "        # We temporarily lower max gen len\n",
        "        self.generator.max_gen_len = 1\n",
        "        _, lls, _ = self.generator.generate(prompts)\n",
        "        results = []\n",
        "        for ll in lls:\n",
        "            results.append((ll.sum().item(),))\n",
        "        self.generator.max_gen_len = max_gen_len\n",
        "\n",
        "        return results\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_ppl_on_path(\n",
        "    *,\n",
        "    world_rank: int,\n",
        "    world_size: int,\n",
        "    model: LMTransformer | ByteLatentTransformer,\n",
        "    tokenizer_args: TokenizerArgs,\n",
        "    patcher_args: PatcherArgs,\n",
        "    packing_args: PackingArgs,\n",
        "    add_patches: bool,\n",
        "    path: str,\n",
        "    arrow_batch_size: int,\n",
        "    max_n_docs: int | None,\n",
        "    max_n_batches: int | None,\n",
        "    s3_profile: str | None = None,\n",
        "):\n",
        "    model.eval()\n",
        "    seq_len = model.get_output_seq_len()\n",
        "    arrow_iterator = ArrowFileIterator(\n",
        "        file_path=None,\n",
        "        dataset_files=[path],\n",
        "        entropy_model_name=None,\n",
        "        worker_id=world_rank,\n",
        "        num_workers=world_size,\n",
        "        arrow_batch_size=arrow_batch_size,\n",
        "        preprocess_dir=None,\n",
        "        s3_profile=s3_profile,\n",
        "        file_format=\"arrow\" if path.endswith(\"arrow\") else \"json\",\n",
        "    )\n",
        "    if max_n_docs is not None:\n",
        "        arrow_iterator = LimitIterator(arrow_iterator, limit=max_n_docs)\n",
        "    preprocess_iterator = PreprocessIterator(\n",
        "        arrow_iterator,\n",
        "        patcher_args=patcher_args,\n",
        "        tokenizer_args=tokenizer_args,\n",
        "        add_patches=add_patches,\n",
        "    )\n",
        "    sequence_iterator = SequenceIterator(\n",
        "        preprocess_iterator,\n",
        "        sequence_packing_args=SequencePackingArgs(\n",
        "            output_seq_len=seq_len,\n",
        "            # Effectively disables shuffles\n",
        "            buffer_size=1,\n",
        "        ),\n",
        "        rng_state=None,\n",
        "    )\n",
        "    packing_iterator = PackingIterator(sequence_iterator, packing_args=packing_args)\n",
        "    total_loss = 0.0\n",
        "    n_bytes = 0\n",
        "    batch_iterator = packing_iterator.create_iter()\n",
        "    for i, batch in enumerate(batch_iterator):\n",
        "        if i == max_n_batches:\n",
        "            break\n",
        "        x = torch.from_numpy(batch.x).cuda()\n",
        "        y = torch.from_numpy(batch.y).cuda()\n",
        "        mask = None if batch.mask is None else torch.from_numpy(batch.mask).cuda()\n",
        "        patch_lengths = batch.patch_lengths\n",
        "        if patch_lengths is not None:\n",
        "            patch_lengths = torch.from_numpy(patch_lengths).cuda()\n",
        "\n",
        "        if tokenizer_args.name in [\"bytes\", \"blt\"]:\n",
        "            n_bytes += y.numel() if mask is None else mask.sum().item()\n",
        "            if isinstance(model, ByteLatentTransformer):\n",
        "                pred = model(x, patch_lengths=patch_lengths)\n",
        "            else:\n",
        "                pred = model(x)\n",
        "            loss = F.cross_entropy(\n",
        "                pred.flatten(0, 1), y.flatten(0, 1), reduction=\"sum\", ignore_index=0\n",
        "            )\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            raise NotImplementedError()\n",
        "    all_n_bytes = to_py_num(dist_sum(n_bytes))\n",
        "    all_total_loss = to_py_num(dist_sum(total_loss))\n",
        "    return {\n",
        "        \"n_bytes\": all_n_bytes,\n",
        "        \"n_bytes_gpu\": n_bytes,\n",
        "        \"loss_sum\": all_total_loss,\n",
        "        \"loss_sum_gpu\": total_loss,\n",
        "        \"loss_mean\": all_total_loss / all_n_bytes,\n",
        "        \"loss_mean_gpu\": total_loss / n_bytes,\n",
        "        \"ppl\": math.exp(all_total_loss / all_n_bytes) if all_n_bytes > 0 else 0.0,\n",
        "        \"bpb\": all_total_loss / math.log(2) / all_n_bytes,\n",
        "    }\n",
        "\n",
        "\n",
        "def launch_eval(eval_args: EvalArgs):\n",
        "    assert eval_args.dump_dir is not None\n",
        "    assert eval_args.ckpt_dir is not None\n",
        "    distributed_args = DistributedArgs()\n",
        "    distributed_args.configure_world()\n",
        "    if not torch.distributed.is_initialized():\n",
        "        setup_torch_distributed(distributed_args)\n",
        "\n",
        "    world_mesh = get_device_mesh(distributed_args)\n",
        "    dp_mesh = world_mesh[\"dp_replicate\"]\n",
        "    assert distributed_args.dp_shard == 1\n",
        "    world_size = dp_mesh.size()\n",
        "    world_rank = dp_mesh.get_local_rank()\n",
        "\n",
        "    fs = get_fs(eval_args.ckpt_dir, s3_profile=eval_args.s3_profile)\n",
        "    if (\n",
        "        fs.exists(eval_args.ckpt_dir)\n",
        "        and fs.exists(os.path.join(eval_args.ckpt_dir, \"params.json\"))\n",
        "        and len(fs.glob(os.path.join(eval_args.ckpt_dir, \"*.pth\"))) != 0\n",
        "    ):\n",
        "        consolidate_path = eval_args.ckpt_dir\n",
        "    else:\n",
        "        if eval_args.consolidate_if_needed:\n",
        "            logger.info(\n",
        "                \"Found a model checkpoint, but it has not been consolidated.... so consolidating the checkpoint\"\n",
        "            )\n",
        "            consolidate_path = os.path.join(\n",
        "                eval_args.ckpt_dir, eval_args.consolidate_folder\n",
        "            )\n",
        "            if not fs.exists(consolidate_path) and get_global_rank() == 0:\n",
        "                consolidate_path = consolidate_checkpoints(fs, eval_args.ckpt_dir)\n",
        "            logger.info(\"Model consolidated to: %s\", consolidate_path)\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                \"Did not find a consolidated checkpoint and consolidate_if_needed is False\"\n",
        "            )\n",
        "\n",
        "    fs.mkdirs(eval_args.dump_dir, exist_ok=True)\n",
        "    with fs.open(os.path.join(eval_args.dump_dir, \"config.yaml\"), \"w\") as f:\n",
        "        f.write(eval_args.model_dump_json())\n",
        "\n",
        "    torch.distributed.barrier()\n",
        "    logger.info(\"Loading model\")\n",
        "    model, tokenizer, train_cfg = load_consolidated_model_and_tokenizer(\n",
        "        consolidate_path,\n",
        "    )\n",
        "    pad_id = 0 if train_cfg.data.tokenizer_args.name == \"bytes\" else tokenizer.boe_id\n",
        "    model.eval()\n",
        "    logger.info(\"Model loaded\")\n",
        "\n",
        "    ppl_results = None\n",
        "    if eval_args.run_ppl:\n",
        "        assert eval_args.validation is not None\n",
        "        packing_args = PackingArgs(\n",
        "            batch_size=eval_args.validation.batch_size,\n",
        "            seq_len=train_cfg.data.seq_len,\n",
        "            max_length=train_cfg.data.max_encoder_seq_length,\n",
        "            pad_to_max_length=True,\n",
        "            enable_byte_ngrams=False,\n",
        "            pad_id=pad_id,\n",
        "            packing_mode=(\n",
        "                PackingMode.BYTES\n",
        "                if train_cfg.data.patcher_args.patching_mode == PatchingModeEnum.byte\n",
        "                else PackingMode.PATCHING\n",
        "            ),\n",
        "        )\n",
        "        if len(eval_args.validation.sources) > 0:\n",
        "            ppl_results = {}\n",
        "            logger.info(\"Starting PPL evaluation on validation sets\")\n",
        "            for source in eval_args.validation.sources:\n",
        "                ppl_results[source] = eval_ppl_on_path(\n",
        "                    world_rank=world_rank,\n",
        "                    world_size=world_size,\n",
        "                    model=model,\n",
        "                    tokenizer_args=train_cfg.data.tokenizer_args,\n",
        "                    patcher_args=train_cfg.data.patcher_args,\n",
        "                    packing_args=packing_args,\n",
        "                    add_patches=train_cfg.data.add_patches,\n",
        "                    path=os.path.join(eval_args.validation.root_dir, source),\n",
        "                    max_n_docs=eval_args.validation.max_n_docs,\n",
        "                    max_n_batches=eval_args.validation.max_n_batches,\n",
        "                    arrow_batch_size=20,\n",
        "                    s3_profile=eval_args.s3_profile,\n",
        "                )\n",
        "\n",
        "    task_results = None\n",
        "    if eval_args.run_tasks:\n",
        "        assert eval_args.generator is not None\n",
        "        assert eval_args.harness is not None\n",
        "        generator = PackedCausalTransformerGenerator(\n",
        "            eval_args.generator, model, tokenizer\n",
        "        )\n",
        "        wrap = EvalHarnessLM(generator)\n",
        "        # TODO: This needs to be checked/sped up\n",
        "        task_results = simple_evaluate(wrap, **eval_args.harness.model_dump())\n",
        "\n",
        "    results = {\"ppl\": ppl_results, \"tasks\": task_results}\n",
        "    # TODO: Serial and Parallel yield slightly different number of bytes, debug this later,\n",
        "    # leaving this log statement here to help with that.\n",
        "    # logging.info(\"Rank: %s Results: %s\", world_rank, results)\n",
        "\n",
        "    if get_global_rank() == 0:\n",
        "        with fs.open(os.path.join(eval_args.dump_dir, \"results.json\"), \"w\") as f:\n",
        "            f.write(json.dumps(results))\n",
        "        logger.info(f\"All evaluation results: {results}\")\n",
        "        if ppl_results is not None:\n",
        "            with fs.open(os.path.join(eval_args.dump_dir, \"validation.json\"), \"w\") as f:\n",
        "                f.write(json.dumps(ppl_results))\n",
        "            logger.info(f\"All validation results: {ppl_results}\")\n",
        "\n",
        "    if eval_args.metric_log_dir and get_global_rank() == 0:\n",
        "        metric_log_path = os.path.join(eval_args.metric_log_dir, \"metrics.eval.jsonl\")\n",
        "\n",
        "        logger.info(f\"Writing metric logs to {metric_log_path}\")\n",
        "        timestamp: dict[str, int | str] = {\n",
        "            \"created_at\": datetime.utcnow().isoformat(),\n",
        "        }\n",
        "        if eval_args.global_step is not None:\n",
        "            timestamp[\"global_step\"] = eval_args.global_step\n",
        "        print(\n",
        "            json.dumps(timestamp | results),\n",
        "            file=fs.open(metric_log_path, mode=\"a\"),\n",
        "            flush=True,\n",
        "        )\n",
        "\n",
        "        val_log_path = os.path.join(\n",
        "            eval_args.metric_log_dir, \"metrics.validation.jsonl\"\n",
        "        )\n",
        "        if ppl_results is not None:\n",
        "            print(\n",
        "                json.dumps(timestamp | ppl_results),\n",
        "                file=fs.open(val_log_path, mode=\"a\"),\n",
        "                flush=True,\n",
        "            )\n",
        "\n",
        "\n",
        "def main():\n",
        "    eval_args = parse_args_to_pydantic_model(EvalArgs)\n",
        "    launch_eval(eval_args)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "Izbm09-sOuaO",
        "outputId": "4b938776-e6e1-4541-b785-268ab65e9d30"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'_OpNamespace' 'xformers' object has no attribute 'efficient_attention_forward_cutlass'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-77d12166be3b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m from bytelatent.args import (\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mEvalArgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mTrainArgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/blt/bytelatent/args.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydantic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConfigDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbytelatent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCONSOLIDATE_FOLDER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCheckpointArgs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbytelatent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_types\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbytelatent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_fs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/blt/bytelatent/checkpoint.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbytelatent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_fs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbytelatent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_is_master\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CHECKPOINT\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/blt/bytelatent/distributed.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BLT_ALLOW_MISSING_FLEX_ATTENTION\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     default_no_recompute_ops.add(\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mefficient_attention_forward_cutlass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     )\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, op_name)\u001b[0m\n\u001b[1;32m   1230\u001b[0m             \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverload_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_packet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqualified_op_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mop\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1232\u001b[0;31m                 raise AttributeError(\n\u001b[0m\u001b[1;32m   1233\u001b[0m                     \u001b[0;34mf\"'_OpNamespace' '{self.name}' object has no attribute '{op_name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m                 )\n",
            "\u001b[0;31mAttributeError\u001b[0m: '_OpNamespace' 'xformers' object has no attribute 'efficient_attention_forward_cutlass'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from huggingface_hub import PyTorchModelHubMixin\n",
        "\n",
        "class ByteLatentTransformer(\n",
        "    nn.Module,\n",
        "    SequenceModelWithOutput,\n",
        "    PyTorchModelHubMixin,\n",
        "    repo_url=\"https://github.com/facebookresearch/blt\",\n",
        "    pipeline_tag=\"text-generation\",\n",
        "    coders={\n",
        "        ByteLatentTransformerArgs: (\n",
        "            lambda x: x.dict(),\n",
        "            lambda data: ByteLatentTransformerArgs.model_validate(**data),\n",
        "        ),\n",
        "    },\n",
        "    license=\"other\"\n",
        "):\n",
        "\n",
        "    def __init__(self, args: ByteLatentTransformerArgs):\n",
        "        (...)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "WJaoh-0wPx3X",
        "outputId": "93b82620-ce38-4ae2-a836-6caf8f6375ce"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'SequenceModelWithOutput' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-933bc03daf3c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m class ByteLatentTransformer(\n\u001b[1;32m      5\u001b[0m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mSequenceModelWithOutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mPyTorchModelHubMixin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mrepo_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"https://github.com/facebookresearch/blt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SequenceModelWithOutput' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/blt\n",
        "\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import typer\n",
        "\n",
        "from bytelatent.distributed import DistributedArgs, setup_torch_distributed\n",
        "from bytelatent.generate import load_consolidated_model_and_tokenizer\n",
        "from bytelatent.generate_blt import generate_nocache\n",
        "from bytelatent.model.blt import ByteLatentTransformer\n",
        "from bytelatent.tokenizers.blt_tokenizer import BltTokenizer\n",
        "\n",
        "\n",
        "def main(prompt: str, model_name: str = \"blt-1b\"):\n",
        "    distributed_args = DistributedArgs()\n",
        "    distributed_args.configure_world()\n",
        "    if not torch.distributed.is_initialized():\n",
        "        setup_torch_distributed(distributed_args)\n",
        "    checkpoint_path = os.path.join(\"hf-weights\", model_name)\n",
        "    print(f\"Loading BLT model: {model_name}\")\n",
        "    model, tokenizer, train_cfg = load_consolidated_model_and_tokenizer(\n",
        "        checkpoint_path,\n",
        "    )\n",
        "    assert isinstance(model, ByteLatentTransformer)\n",
        "    assert isinstance(tokenizer, BltTokenizer)\n",
        "    patcher_args = train_cfg.data.patcher_args.model_copy(deep=True)\n",
        "    patcher_args.realtime_patching = True\n",
        "    print(\"Loading entropy model and patcher\")\n",
        "    patcher_args.entropy_model_checkpoint_dir = os.path.join(\n",
        "        checkpoint_path, \"entropy_model\"\n",
        "    )\n",
        "    patcher = patcher_args.build()\n",
        "    prompts = [prompt]\n",
        "    outputs = generate_nocache(\n",
        "        prompts, model=model, tokenizer=tokenizer, patcher=patcher\n",
        "    )\n",
        "    text_outputs = [tokenizer.decode(t) for t in outputs]\n",
        "    for p, t in zip(prompts, text_outputs):\n",
        "        print(f'Prompt: \"{p}\" Completion: \"{t}\"')\n",
        "        print()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    typer.run(main)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "4CvWl6ZmZhsS",
        "outputId": "bdab3408-e771-4011-c511-8e854ce8f832"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/blt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'_OpNamespace' 'xformers' object has no attribute 'efficient_attention_forward_cutlass'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-9b725262043f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtyper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbytelatent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDistributedArgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetup_torch_distributed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbytelatent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_consolidated_model_and_tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbytelatent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_blt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgenerate_nocache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/blt/bytelatent/distributed.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BLT_ALLOW_MISSING_FLEX_ATTENTION\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     default_no_recompute_ops.add(\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mefficient_attention_forward_cutlass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     )\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, op_name)\u001b[0m\n\u001b[1;32m   1230\u001b[0m             \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverload_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_packet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqualified_op_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mop\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1232\u001b[0;31m                 raise AttributeError(\n\u001b[0m\u001b[1;32m   1233\u001b[0m                     \u001b[0;34mf\"'_OpNamespace' '{self.name}' object has no attribute '{op_name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m                 )\n",
            "\u001b[0;31mAttributeError\u001b[0m: '_OpNamespace' 'xformers' object has no attribute 'efficient_attention_forward_cutlass'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel\n",
        "from torch import nn\n",
        "from huggingface_hub import PyTorchModelHubMixin\n",
        "\n",
        "class ByteLatentTransformer(nn.Module, SequenceModelWithOutput, PyTorchModelHubMixin,\n",
        "from pydantic import BaseModel\n",
        "from torch import nn\n",
        "from huggingface_hub import PyTorchModelHubMixin\n",
        "\n",
        "class ByteLatentTransformer(nn.Module, PyTorchModelHubMixin): # removed SequenceModelWithOutput as it's not defined\n",
        "    repo_url = \"https://github.com/facebookresearch/blt\"\n",
        "    pipeline_tag = \"text-generation\"\n",
        "    _coders = {\n",
        "        BaseModel: (\n",
        "            lambda x: x.dict(),  # Encoder: how to convert a `BaseModel` to a valid jsonable value?\n",
        "            lambda data: BaseModel.model_validate(**data),  # Decoder: how to reconstruct a `BaseModel` from a dictionary, corrected to use BaseModel.model_validate\n",
        "        )\n",
        "    }\n",
        "    license=\"other\"\n",
        "    def __init__(self, args: BaseModel): # Type hint changed to BaseModel as ByteLatentTransformerArgs isn't defined\n",
        "\n",
        "        super().__init__()\n",
        "from pydantic import BaseModel\n",
        "from torch import nn\n",
        "from huggingface_hub import PyTorchModelHubMixin\n",
        "\n",
        "class ByteLatentTransformer(nn.Module, PyTorchModelHubMixin): # removed SequenceModelWithOutput as it's not defined\n",
        "    repo_url = \"https://github.com/facebookresearch/blt\"\n",
        "    pipeline_tag = \"text-generation\"\n",
        "    _coders = {\n",
        "        BaseModel: (\n",
        "            lambda x: x.dict(),  # Encoder: how to convert a `BaseModel` to a valid jsonable value?\n",
        "            lambda data: BaseModel.model_validate(**data),  # Decoder: how to reconstruct a `BaseModel` from a dictionary, corrected to use BaseModel.model_validate\n",
        "        )\n",
        "    }\n",
        "    license=\"other\"\n",
        "    def __init__(self, args: BaseModel): # Type hint changed to BaseModel as ByteLatentTransformerArgs isn't defined\n",
        "        super().__init__()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "s4QOhLZRZ8MR",
        "outputId": "15d6ae45-c253-4f65-d439-e90df22c8fb6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "unmatched '}' (<ipython-input-18-10aa2e759d28>, line 25)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-10aa2e759d28>\"\u001b[0;36m, line \u001b[0;32m25\u001b[0m\n\u001b[0;31m    }\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched '}'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel\n",
        "from torch import nn\n",
        "from huggingface_hub import PyTorchModelHubMixin\n",
        "\n",
        "class ByteLatentTransformer(nn.Module, PyTorchModelHubMixin): # removed SequenceModelWithOutput as it's not defined\n",
        "    repo_url = \"https://github.com/facebookresearch/blt\"\n",
        "    pipeline_tag = \"text-generation\"\n",
        "    _coders = {\n",
        "        from pydantic import BaseModel\n",
        "from torch import nn\n",
        "from huggingface_hub import PyTorchModelHubMixin\n",
        "\n",
        "class ByteLatentTransformer(nn.Module, PyTorchModelHubMixin): # removed SequenceModelWithOutput as it's not defined\n",
        "    repo_url = \"https://github.com/facebookresearch/blt\"\n",
        "    pipeline_tag = \"text-generation\"\n",
        "    _coders = {\n",
        "        BaseModel: (\n",
        "        BaseModel: ("
      ],
      "metadata": {
        "id": "6chy1pvrbkl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "%cd /content/blt\n",
        "import bytelatent\n",
        "import os\n",
        "import transformer\n",
        "from pydantic import BaseModel\n",
        "from torch import nn\n",
        "from huggingface_hub import PyTorchModelHubMixin\n",
        "import xformers\n",
        "class ByteLatentTransformer(\n",
        "    nn.Module,\n",
        "    SequenceModelWithOutput,\n",
        "    PyTorchModelHubMixin,\n",
        "    repo_url=\"https://github.com/facebookresearch/blt\",\n",
        "    pipeline_tag=\"text-generation\",\n",
        "    _coders={\n",
        "        ByteLatentTransformerArgs: (\n",
        "            lambda x: x.dict(),\n",
        "            lambda data: ByteLatentTransformerArgs.model_validate(**data),\n",
        "        ),\n",
        "    },\n",
        "    license=\"other\"\n",
        "):\n",
        "    def __init__(self, args: ByteLatentTransformerArgs):\n",
        "        super().__init__()\n",
        "        # ... your model initialization logic here ..."
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "a6O8ps_qb2Y-",
        "outputId": "5c799f4c-7e29-4746-b2d3-c09fc323a9cd"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/blt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'transformer'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-037bb4c66a91>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbytelatent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydantic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformer'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/blt/bytelatent/train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBOP5SgLb6s6",
        "outputId": "57f89b48-481d-4fea-ff30-43b1189cc6da"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/blt/bytelatent/train.py\", line 27, in <module>\n",
            "    from bytelatent.args import TrainArgs\n",
            "  File \"/content/blt/bytelatent/args.py\", line 10, in <module>\n",
            "    from bytelatent.checkpoint import CONSOLIDATE_FOLDER, CheckpointArgs\n",
            "  File \"/content/blt/bytelatent/checkpoint.py\", line 26, in <module>\n",
            "    from bytelatent.distributed import get_is_master\n",
            "  File \"/content/blt/bytelatent/distributed.py\", line 54, in <module>\n",
            "    torch.ops.xformers.efficient_attention_forward_cutlass.default\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_ops.py\", line 1232, in __getattr__\n",
            "    raise AttributeError(\n",
            "AttributeError: '_OpNamespace' 'xformers' object has no attribute 'efficient_attention_forward_cutlass'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash /content/blt/setup/create_env.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhdT4V7Sc13q",
        "outputId": "7c965d0f-6a65-46d3-f47f-4e9e334f9c79"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/blt/setup/create_env.sh: line 28: /etc/profile.d/conda.sh: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from huggingface_hub import PyTorchModelHubMixin\n",
        "\n",
        "class MyModel(\n",
        "        nn.Module,\n",
        "        PyTorchModelHubMixin,\n",
        "        library_name=\"keras-nlp\",\n",
        "        repo_url=\"https://github.com/keras-team/keras-nlp\",\n",
        "        paper_url=\"https://arxiv.org/abs/2304.12244\",\n",
        "        docs_url=\"https://keras.io/keras_nlp/\",\n",
        "        # ^ optional metadata to generate model card\n",
        "    ):\n",
        "    def __init__(self, hidden_size: int = 512, vocab_size: int = 30000, output_size: int = 4):\n",
        "        super().__init__()\n",
        "        self.param = nn.Parameter(torch.rand(hidden_size, vocab_size))\n",
        "        self.linear = nn.Linear(output_size, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x + self.param)\n",
        "model = MyModel(hidden_size=256)\n",
        "\n",
        "model.save_pretrained(\"my-awesome-model\")\n",
        "\n",
        "model.push_to_hub(\"my-awesome-model\")\n",
        "\n",
        "model = MyModel.from_pretrained(\"username/my-awesome-model\")\n",
        "model.hidden_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "id": "cTAObKQCdKyK",
        "outputId": "a81e9c62-52d1-48e4-b082-d41c0a2bc4b0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "HfHubHTTPError",
          "evalue": "(Request ID: Root=1-68085051-51931b67123703d724f13ef6;7633ebd2-9bd2-4288-a503-178e71915b74)\n\n403 Forbidden: You don't have the rights to create a model under the namespace \"rakmik\".\nCannot access content at: https://huggingface.co/api/repos/create.\nMake sure your token has the correct permissions.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://huggingface.co/api/repos/create",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-256d96339753>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"my-awesome-model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush_to_hub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"my-awesome-model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"username/my-awesome-model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hub_mixin.py\u001b[0m in \u001b[0;36mpush_to_hub\u001b[0;34m(self, repo_id, config, commit_message, private, token, branch, create_pr, allow_patterns, ignore_patterns, delete_patterns, model_card_kwargs)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \"\"\"\n\u001b[1;32m    684\u001b[0m         \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHfApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0mrepo_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_repo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprivate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprivate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m         \u001b[0;31m# Push the files to the repo in a single commit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hf_api.py\u001b[0m in \u001b[0;36mcreate_repo\u001b[0;34m(self, repo_id, token, private, repo_type, exist_ok, resource_group_id, space_sdk, space_hardware, space_storage, space_sleep_time, space_secrets, space_variables)\u001b[0m\n\u001b[1;32m   3720\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mRepoUrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.endpoint}/{repo_type}/{repo_id}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3721\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mHfHubHTTPError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3722\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3723\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3724\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hf_api.py\u001b[0m in \u001b[0;36mcreate_repo\u001b[0;34m(self, repo_id, token, private, repo_type, exist_ok, resource_group_id, space_sdk, space_hardware, space_storage, space_sleep_time, space_secrets, space_variables)\u001b[0m\n\u001b[1;32m   3707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3708\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3709\u001b[0;31m             \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3710\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3711\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mexist_ok\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m409\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    471\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\nMake sure your token has the correct permissions.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             )\n\u001b[0;32m--> 473\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHfHubHTTPError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m416\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHfHubHTTPError\u001b[0m: (Request ID: Root=1-68085051-51931b67123703d724f13ef6;7633ebd2-9bd2-4288-a503-178e71915b74)\n\n403 Forbidden: You don't have the rights to create a model under the namespace \"rakmik\".\nCannot access content at: https://huggingface.co/api/repos/create.\nMake sure your token has the correct permissions."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/blt\n",
        "\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import typer\n",
        "\n",
        "from bytelatent.distributed import DistributedArgs, setup_torch_distributed\n",
        "from bytelatent.generate import load_consolidated_model_and_tokenizer\n",
        "from bytelatent.generate_blt import generate_nocache\n",
        "from bytelatent.model.blt import ByteLatentTransformer\n",
        "from bytelatent.tokenizers.blt_tokenizer import BltTokenizer\n",
        "\n",
        "\n",
        "def main(prompt: str, model_name: str = \"blt-1b\"):\n",
        "    distributed_args = DistributedArgs()\n",
        "    distributed_args.configure_world()\n",
        "    if not torch.distributed.is_initialized():\n",
        "        setup_torch_distributed(distributed_args)\n",
        "    checkpoint_path = os.path.join(\"hf-weights\", model_name)\n",
        "    print(f\"Loading BLT model: {model_name}\")\n",
        "    model, tokenizer, train_cfg = load_consolidated_model_and_tokenizer(\n",
        "        checkpoint_path,\n",
        "    )\n",
        "    assert isinstance(model, ByteLatentTransformer)\n",
        "    assert isinstance(tokenizer, BltTokenizer)\n",
        "    patcher_args = train_cfg.data.patcher_args.model_copy(deep=True)\n",
        "    patcher_args.realtime_patching = True\n",
        "    print(\"Loading entropy model and patcher\")\n",
        "    patcher_args.entropy_model_checkpoint_dir = os.path.join(\n",
        "        checkpoint_path, \"entropy_model\"\n",
        "    )\n",
        "    patcher = patcher_args.build()\n",
        "    prompts = [prompt]\n",
        "    outputs = generate_nocache(\n",
        "        prompts, model=model, tokenizer=tokenizer, patcher=patcher\n",
        "    )\n",
        "    text_outputs = [tokenizer.decode(t) for t in outputs]\n",
        "    for p, t in zip(prompts, text_outputs):\n",
        "        print(f'Prompt: \"{p}\" Completion: \"{t}\"')\n",
        "        print()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    typer.run(main)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "nH5vGXGpe60l",
        "outputId": "f0cbc7ae-5d55-41aa-9533-c37ec013d7bd"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/blt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'_OpNamespace' 'xformers' object has no attribute 'efficient_attention_forward_cutlass'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-9b725262043f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtyper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbytelatent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDistributedArgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetup_torch_distributed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbytelatent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_consolidated_model_and_tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbytelatent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_blt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgenerate_nocache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/blt/bytelatent/distributed.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BLT_ALLOW_MISSING_FLEX_ATTENTION\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     default_no_recompute_ops.add(\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mefficient_attention_forward_cutlass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     )\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, op_name)\u001b[0m\n\u001b[1;32m   1230\u001b[0m             \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverload_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_packet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqualified_op_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mop\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1232\u001b[0;31m                 raise AttributeError(\n\u001b[0m\u001b[1;32m   1233\u001b[0m                     \u001b[0;34mf\"'_OpNamespace' '{self.name}' object has no attribute '{op_name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m                 )\n",
            "\u001b[0;31mAttributeError\u001b[0m: '_OpNamespace' 'xformers' object has no attribute 'efficient_attention_forward_cutlass'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# Start timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Get the current date\n",
        "current_date = datetime.now().strftime(\"%y%m%d\")\n",
        "env_prefix = f\"blt_{current_date}\"\n",
        "print(f\"Environment prefix (used as label only): {env_prefix}\")\n",
        "\n",
        "# Install packages\n",
        "!pip install torch==2.5.0 xformers --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install ninja\n",
        "\n",
        "# If requirements.txt is available in path, install from it\n",
        "requirements_path = 'blt/setup/requirements.txt'\n",
        "if os.path.exists(requirements_path):\n",
        "    !pip install -r {requirements_path}\n",
        "else:\n",
        "    print(\"⚠️ requirements.txt not found, skipping...\")\n",
        "\n",
        "# End timer\n",
        "end_time = time.time()\n",
        "elapsed_minutes = (end_time - start_time) / 60\n",
        "print(f\"✅ All packages installed in {elapsed_minutes:.2f} minutes!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "l1c_dG1Ge9lT",
        "outputId": "fcf042c4-a2bd-44ec-ab38-a6fb9a981c42"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment prefix (used as label only): blt_250423\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting torch==2.5.0\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.5.0%2Bcu121-cp311-cp311-linux_x86_64.whl (780.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.5/780.5 MB\u001b[0m \u001b[31m747.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: xformers in /usr/local/lib/python3.11/dist-packages (0.0.29.post3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (2024.12.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (9.1.0.70)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (2.21.5)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.1.0 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.5.0) (12.4.127)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.0) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xformers) (2.0.2)\n",
            "INFO: pip is looking at multiple versions of xformers to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting xformers\n",
            "  Downloading https://download.pytorch.org/whl/cu121/xformers-0.0.29.post1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/xformers-0.0.29-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/xformers-0.0.28.post3-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/xformers-0.0.28.post2-cp311-cp311-manylinux_2_28_x86_64.whl (16.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.5.0) (3.0.2)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, torch, xformers\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n",
            "    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.5.147\n",
            "    Uninstalling nvidia-curand-cu12-10.3.5.147:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n",
            "    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: xformers\n",
            "    Found existing installation: xformers 0.0.29.post3\n",
            "    Uninstalling xformers-0.0.29.post3:\n",
            "      Successfully uninstalled xformers-0.0.29.post3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.5.0+cu121 which is incompatible.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.5.0+cu121 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nvtx-cu12-12.1.105 torch-2.5.0+cu121 triton-3.1.0 xformers-0.0.28.post2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "functorch",
                  "nvidia",
                  "torch",
                  "torchgen",
                  "triton",
                  "xformers"
                ]
              },
              "id": "90de91ca92f74cb0928b715e68e9ea85"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ninja\n",
            "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
            "Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/422.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m419.8/422.8 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 447, in run\n",
            "^C\n",
            "⚠️ requirements.txt not found, skipping...\n",
            "✅ All packages installed in 3.15 minutes!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/blt\n",
        "\n",
        "!python demo.py \"A BLT has\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "If_83tH3haMk",
        "outputId": "21c2bc17-26c3-412d-e57c-577f7c5917e6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/blt\n",
            "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/blt/\u001b[0m\u001b[1;33mdemo.py\u001b[0m:\u001b[94m17\u001b[0m in \u001b[92mmain\u001b[0m                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m14 \u001b[0m\u001b[2m│   \u001b[0mdistributed_args = DistributedArgs()                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m15 \u001b[0m\u001b[2m│   \u001b[0mdistributed_args.configure_world()                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m16 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m torch.distributed.is_initialized():                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m17 \u001b[2m│   │   \u001b[0m\u001b[1;4msetup_torch_distributed(distributed_args)\u001b[0m                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m18 \u001b[0m\u001b[2m│   \u001b[0mcheckpoint_path = os.path.join(\u001b[33m\"\u001b[0m\u001b[33mhf-weights\u001b[0m\u001b[33m\"\u001b[0m, model_name)            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m19 \u001b[0m\u001b[2m│   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mLoading BLT model: \u001b[0m\u001b[33m{\u001b[0mmodel_name\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m)                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m20 \u001b[0m\u001b[2m│   \u001b[0mmodel, tokenizer, train_cfg = load_consolidated_model_and_tokenizer \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m─────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m──────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m distributed_args = \u001b[1;35mDistributedArgs\u001b[0m\u001b[1m(\u001b[0m                                 \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mdp_shard\u001b[0m=\u001b[94m1\u001b[0m,                                  \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mdp_replicate\u001b[0m=\u001b[94m1\u001b[0m,                              \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mtp_size\u001b[0m=\u001b[94m1\u001b[0m,                                   \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mselective_activation_checkpointing\u001b[0m=\u001b[94mFalse\u001b[0m,    \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mcompile\u001b[0m=\u001b[94mFalse\u001b[0m,                               \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mfsdp_type\u001b[0m=\u001b[33m'no_shard'\u001b[0m,                        \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mmodel_dtype\u001b[0m=\u001b[33m'bf16'\u001b[0m,                          \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mfloat8_recipe\u001b[0m=\u001b[94mNone\u001b[0m,                          \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mfloat8_filter\u001b[0m=\u001b[33m'layers\\\\.\u001b[0m\u001b[1;33m[\u001b[0m\u001b[33m0-9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[33m+\\\\.'\u001b[0m,          \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mmatmul_allow_tf32\u001b[0m=\u001b[94mFalse\u001b[0m,                     \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mallow_bf16_reduced_precision_reduction\u001b[0m=\u001b[94mTrue\u001b[0m, \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mdetect_anomaly\u001b[0m=\u001b[94mFalse\u001b[0m,                        \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mcompile_cache_size_limit\u001b[0m=\u001b[94m8\u001b[0m,                  \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mspawn_method\u001b[0m=\u001b[33m'forkserver'\u001b[0m                    \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[1m)\u001b[0m                                                \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m       model_name = \u001b[33m'blt-1b'\u001b[0m                                         \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m           prompt = \u001b[33m'A BLT has'\u001b[0m                                      \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰─────────────────────────────────────────────────────────────────────╯\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/blt/bytelatent/\u001b[0m\u001b[1;33mdistributed.py\u001b[0m:\u001b[94m338\u001b[0m in \u001b[92msetup_torch_distributed\u001b[0m        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m335 \u001b[0m\u001b[2m│   \u001b[0m)                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m336 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m torch.cuda.device_count() > \u001b[94m1\u001b[0m:                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m337 \u001b[0m\u001b[2m│   │   \u001b[0mtorch.cuda.set_device(local_rank)                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m338 \u001b[2m│   \u001b[0m\u001b[1;4mtorch.distributed.init_process_group(init_method=\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33menv://\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4m, backend\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m339 \u001b[0m\u001b[2m│   \u001b[0mtorch.autograd.set_detect_anomaly(dist_args.detect_anomaly)        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m340 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m341 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m──────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m───────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m  dist_args = \u001b[1;35mDistributedArgs\u001b[0m\u001b[1m(\u001b[0m                                 \u001b[33m│\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              \u001b[2m│   \u001b[0m\u001b[33mdp_shard\u001b[0m=\u001b[94m1\u001b[0m,                                  \u001b[33m│\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              \u001b[2m│   \u001b[0m\u001b[33mdp_replicate\u001b[0m=\u001b[94m1\u001b[0m,                              \u001b[33m│\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              \u001b[2m│   \u001b[0m\u001b[33mtp_size\u001b[0m=\u001b[94m1\u001b[0m,                                   \u001b[33m│\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              \u001b[2m│   \u001b[0m\u001b[33mselective_activation_checkpointing\u001b[0m=\u001b[94mFalse\u001b[0m,    \u001b[33m│\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              \u001b[2m│   \u001b[0m\u001b[33mcompile\u001b[0m=\u001b[94mFalse\u001b[0m,                               \u001b[33m│\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              \u001b[2m│   \u001b[0m\u001b[33mfsdp_type\u001b[0m=\u001b[33m'no_shard'\u001b[0m,                        \u001b[33m│\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              \u001b[2m│   \u001b[0m\u001b[33mmodel_dtype\u001b[0m=\u001b[33m'bf16'\u001b[0m,                          \u001b[33m│\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              \u001b[2m│   \u001b[0m\u001b[33mfloat8_recipe\u001b[0m=\u001b[94mNone\u001b[0m,                          \u001b[33m│\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              \u001b[2m│   \u001b[0m\u001b[33mfloat8_filter\u001b[0m=\u001b[33m'layers\\\\.\u001b[0m\u001b[1;33m[\u001b[0m\u001b[33m0-9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[33m+\\\\.'\u001b[0m,          \u001b[33m│\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              \u001b[2m│   \u001b[0m\u001b[33mmatmul_allow_tf32\u001b[0m=\u001b[94mFalse\u001b[0m,                     \u001b[33m│\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              \u001b[2m│   \u001b[0m\u001b[33mallow_bf16_reduced_precision_reduction\u001b[0m=\u001b[94mTrue\u001b[0m, \u001b[33m│\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              \u001b[2m│   \u001b[0m\u001b[33mdetect_anomaly\u001b[0m=\u001b[94mFalse\u001b[0m,                        \u001b[33m│\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              \u001b[2m│   \u001b[0m\u001b[33mcompile_cache_size_limit\u001b[0m=\u001b[94m8\u001b[0m,                  \u001b[33m│\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              \u001b[2m│   \u001b[0m\u001b[33mspawn_method\u001b[0m=\u001b[33m'forkserver'\u001b[0m                    \u001b[33m│\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              \u001b[1m)\u001b[0m                                                \u001b[33m│\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m local_rank = \u001b[94m0\u001b[0m                                                \u001b[33m│\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰───────────────────────────────────────────────────────────────╯\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/torch/distributed/\u001b[0m\u001b[1;33mc10d_logger.py\u001b[0m:\u001b[94m83\u001b[0m  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m in \u001b[92mwrapper\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 80 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@functools\u001b[0m.wraps(func)                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 81 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mwrapper\u001b[0m(*args: _P.args, **kwargs: _P.kwargs) -> _T:            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 82 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 83 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwargs)                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 84 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mException\u001b[0m \u001b[94mas\u001b[0m error:                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 85 \u001b[0m\u001b[2m│   │   │   \u001b[0mmsg_dict = _get_msg_dict(func.\u001b[91m__name__\u001b[0m, *args, **kwargs)   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 86 \u001b[0m\u001b[2m│   │   │   \u001b[0mmsg_dict[\u001b[33m\"\u001b[0m\u001b[33merror\u001b[0m\u001b[33m\"\u001b[0m] = \u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m{\u001b[0merror\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     args = \u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                                                            \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m   kwargs = \u001b[1m{\u001b[0m\u001b[33m'init_method'\u001b[0m: \u001b[33m'env://'\u001b[0m, \u001b[33m'backend'\u001b[0m: \u001b[33m'nccl'\u001b[0m\u001b[1m}\u001b[0m                  \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m msg_dict = \u001b[1m{\u001b[0m                                                             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            \u001b[2m│   \u001b[0m\u001b[33m'func_name'\u001b[0m: \u001b[33m'init_process_group'\u001b[0m,                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            \u001b[2m│   \u001b[0m\u001b[33m'args'\u001b[0m: \u001b[33m\"\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m{\u001b[0m\u001b[33m'init_method': 'env://', 'backend': \u001b[0m        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            \u001b[33m'nccl'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[33m\"\u001b[0m,                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            \u001b[2m│   \u001b[0m\u001b[33m'error'\u001b[0m: \u001b[33m'ProcessGroupNCCL is only supported with GPUs, \u001b[0m  \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            \u001b[33mno GPUs found!'\u001b[0m                                               \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            \u001b[1m}\u001b[0m                                                             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/torch/distributed/\u001b[0m\u001b[1;33mc10d_logger.py\u001b[0m:\u001b[94m97\u001b[0m  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m in \u001b[92mwrapper\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 94 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@functools\u001b[0m.wraps(func)                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 95 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mwrapper\u001b[0m(*args: _P.args, **kwargs: _P.kwargs) -> _T:            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 96 \u001b[0m\u001b[2m│   │   \u001b[0mt1 = time.time_ns()                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 97 \u001b[2m│   │   \u001b[0mfunc_return = \u001b[1;4mfunc(*args, **kwargs)\u001b[0m                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 98 \u001b[0m\u001b[2m│   │   \u001b[0mtime_spent = time.time_ns() - t1                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 99 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m100 \u001b[0m\u001b[2m│   │   \u001b[0mmsg_dict = _get_msg_dict(func.\u001b[91m__name__\u001b[0m, *args, **kwargs)       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m──────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m───────────────────────\u001b[0m\u001b[33m─╮\u001b[0m                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m   args = \u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                                           \u001b[33m│\u001b[0m                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m kwargs = \u001b[1m{\u001b[0m\u001b[33m'init_method'\u001b[0m: \u001b[33m'env://'\u001b[0m, \u001b[33m'backend'\u001b[0m: \u001b[33m'nccl'\u001b[0m\u001b[1m}\u001b[0m \u001b[33m│\u001b[0m                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     t1 = \u001b[94m1745376362140240752\u001b[0m                          \u001b[33m│\u001b[0m                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰───────────────────────────────────────────────────────╯\u001b[0m                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/torch/distributed/\u001b[0m\u001b[1;33mdistributed_c10d.p\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[1;33my\u001b[0m:\u001b[94m1527\u001b[0m in \u001b[92minit_process_group\u001b[0m                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1524 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# different systems (e.g. RPC) in case the store is multi\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1525 \u001b[0m\u001b[2m│   │   │   \u001b[0mstore = PrefixStore(\u001b[33m\"\u001b[0m\u001b[33mdefault_pg\u001b[0m\u001b[33m\"\u001b[0m, store)                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1526 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1527 \u001b[2m│   │   \u001b[0mdefault_pg, _ = _new_process_group_helper(                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1528 \u001b[0m\u001b[2m│   │   │   \u001b[0mworld_size,                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1529 \u001b[0m\u001b[2m│   │   │   \u001b[0mrank,                                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1530 \u001b[0m\u001b[2m│   │   │   \u001b[0m[],                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m             backend = \u001b[33m'nccl'\u001b[0m                                             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m           device_id = \u001b[94mNone\u001b[0m                                               \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          group_name = \u001b[33m'0'\u001b[0m                                                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m         init_method = \u001b[33m'env://'\u001b[0m                                           \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          pg_options = \u001b[94mNone\u001b[0m                                               \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                rank = \u001b[94m0\u001b[0m                                                  \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m rendezvous_iterator = \u001b[1m<\u001b[0m\u001b[1;95mgenerator\u001b[0m\u001b[39m object _env_rendezvous_handler at \u001b[0m      \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                       \u001b[94m0x11db3e1b94e0\u001b[0m\u001b[1m>\u001b[0m                                    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m               store = \u001b[1m<\u001b[0m\u001b[1;95mtorch.distributed.distributed_c10d.PrefixStore\u001b[0m\u001b[39m \u001b[0m   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                       \u001b[39mobject at \u001b[0m\u001b[94m0x11db3e1fec70\u001b[0m\u001b[1m>\u001b[0m                          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m             timeout = \u001b[1;35mdatetime.timedelta\u001b[0m\u001b[1m(\u001b[0m\u001b[33mseconds\u001b[0m=\u001b[94m600\u001b[0m\u001b[1m)\u001b[0m                    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          world_size = \u001b[94m1\u001b[0m                                                  \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/torch/distributed/\u001b[0m\u001b[1;33mdistributed_c10d.p\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[1;33my\u001b[0m:\u001b[94m1771\u001b[0m in \u001b[92m_new_process_group_helper\u001b[0m                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1768 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mpg_options.split_color = _process_group_color(global_ \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1769 \u001b[0m\u001b[2m│   │   │   \u001b[0mpg_options.global_ranks_in_group = global_ranks_in_group  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1770 \u001b[0m\u001b[2m│   │   │   \u001b[0mpg_options.group_name = group_name                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1771 \u001b[2m│   │   │   \u001b[0mbackend_class = \u001b[1;4mProcessGroupNCCL(\u001b[0m                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1772 \u001b[0m\u001b[1;2;4m│   │   │   │   \u001b[0m\u001b[1;4mbackend_prefix_store, group_rank, group_size, pg_opti\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1773 \u001b[0m\u001b[1;2;4m│   │   │   \u001b[0m\u001b[1;4m)\u001b[0m                                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1774 \u001b[0m\u001b[2m│   │   │   \u001b[0mbackend_type = ProcessGroup.BackendType.NCCL              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m               backend = \u001b[33m'nccl'\u001b[0m                                           \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        backend_config = cuda:nccl                                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m  backend_prefix_store = \u001b[1m<\u001b[0m\u001b[1;95mtorch.distributed.distributed_c10d.PrefixStore\u001b[0m\u001b[39m \u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                         \u001b[39mobject at \u001b[0m\u001b[94m0x11db3e1fee70\u001b[0m\u001b[1m>\u001b[0m                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m           backend_str = \u001b[33m'nccl'\u001b[0m                                           \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m       base_pg_options = \u001b[1m<\u001b[0m\u001b[1;95mtorch._C._distributed_c10d.ProcessGroup.Options\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                         \u001b[39mobject at \u001b[0m\u001b[94m0x11db3e1fed30\u001b[0m\u001b[1m>\u001b[0m                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                device = \u001b[33m'cuda'\u001b[0m                                           \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m             device_id = \u001b[94mNone\u001b[0m                                             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m global_ranks_in_group = \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m                                               \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            group_desc = \u001b[33m'default_pg'\u001b[0m                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            group_name = \u001b[33m'0'\u001b[0m                                              \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            group_rank = \u001b[94m0\u001b[0m                                                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            group_size = \u001b[94m1\u001b[0m                                                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m      is_default_group = \u001b[94mTrue\u001b[0m                                             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    pg = \u001b[1m<\u001b[0m\u001b[1;95mtorch.distributed.distributed_c10d.ProcessGroup\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                         \u001b[39mobject at \u001b[0m\u001b[94m0x11db3e1fed70\u001b[0m\u001b[1m>\u001b[0m                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            pg_options = \u001b[1m<\u001b[0m\u001b[1;95mtorch._C._distributed_c10d.ProcessGroupNCCL.Op…\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                         \u001b[39mobject at \u001b[0m\u001b[94m0x11db3e1fee30\u001b[0m\u001b[1m>\u001b[0m                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                pg_tag = \u001b[94mNone\u001b[0m                                             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          prefix_store = \u001b[1m<\u001b[0m\u001b[1;95mtorch.distributed.distributed_c10d.PrefixStore\u001b[0m\u001b[39m \u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                         \u001b[39mobject at \u001b[0m\u001b[94m0x11db3e1fecb0\u001b[0m\u001b[1m>\u001b[0m                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            split_from = \u001b[94mNone\u001b[0m                                             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                 store = \u001b[1m<\u001b[0m\u001b[1;95mtorch.distributed.distributed_c10d.PrefixStore\u001b[0m\u001b[39m \u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                         \u001b[39mobject at \u001b[0m\u001b[94m0x11db3e1fec70\u001b[0m\u001b[1m>\u001b[0m                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m               timeout = \u001b[1;35mdatetime.timedelta\u001b[0m\u001b[1m(\u001b[0m\u001b[33mseconds\u001b[0m=\u001b[94m600\u001b[0m\u001b[1m)\u001b[0m                  \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\u001b[1;91mValueError: \u001b[0mProcessGroupNCCL is only supported with GPUs, no GPUs found!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/blt\n",
        "\n",
        "!python /content/blt/bytelatent/train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjWv_r-Cip9_",
        "outputId": "dcfd6ec6-a49f-4243-d865-06b3188b6017"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/blt\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1967, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/integrations/ggml.py\", line 24, in <module>\n",
            "    from tokenizers import Tokenizer, decoders, normalizers, pre_tokenizers, processors\n",
            "ImportError: cannot import name 'Tokenizer' from 'tokenizers' (/content/blt/bytelatent/tokenizers/__init__.py)\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/blt/bytelatent/train.py\", line 53, in <module>\n",
            "    from bytelatent.eval import EVAL_FOLDER_NAME, launch_eval\n",
            "  File \"/content/blt/bytelatent/eval.py\", line 11, in <module>\n",
            "    from lm_eval import simple_evaluate\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/lm_eval/__init__.py\", line 4, in <module>\n",
            "    from .evaluator import evaluate, simple_evaluate\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/lm_eval/evaluator.py\", line 12, in <module>\n",
            "    import lm_eval.api.metrics\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/lm_eval/api/metrics.py\", line 12, in <module>\n",
            "    from lm_eval.api.registry import register_aggregation, register_metric\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/lm_eval/api/registry.py\", line 4, in <module>\n",
            "    import evaluate as hf_evaluate\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/evaluate/__init__.py\", line 29, in <module>\n",
            "    from .evaluation_suite import EvaluationSuite\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/evaluate/evaluation_suite/__init__.py\", line 10, in <module>\n",
            "    from ..evaluator import evaluator\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/evaluate/evaluator/__init__.py\", line 17, in <module>\n",
            "    from transformers.pipelines import SUPPORTED_TASKS as SUPPORTED_PIPELINE_TASKS\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/pipelines/__init__.py\", line 23, in <module>\n",
            "    from ..configuration_utils import PretrainedConfig\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py\", line 27, in <module>\n",
            "    from .modeling_gguf_pytorch_utils import load_gguf_checkpoint\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_gguf_pytorch_utils.py\", line 22, in <module>\n",
            "    from .integrations import (\n",
            "  File \"<frozen importlib._bootstrap>\", line 1229, in _handle_fromlist\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1955, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1969, in _get_module\n",
            "    raise RuntimeError(\n",
            "RuntimeError: Failed to import transformers.integrations.ggml because of the following error (look up to see its traceback):\n",
            "cannot import name 'Tokenizer' from 'tokenizers' (/content/blt/bytelatent/tokenizers/__init__.py)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/blt/setup/download_tokenizer.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQFbLOw0iWe8",
        "outputId": "16f99fbd-52ac-480a-f447-38b40751e272"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: download_tokenizer.py [-h] [--api_key API_KEY]\n",
            "                             tokenizer_name tokenizer_dir\n",
            "download_tokenizer.py: error: the following arguments are required: tokenizer_name, tokenizer_dir\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python setup/download_prepare_hf_data.py fineweb_edu 1 --data_dir ./data --seed 42 --nchunks 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-blm2vXjIYt",
        "outputId": "82cac2ac-8a71-4147-b028-15ed08089ff5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "train-00012-of-00014.parquet:  19% 419M/2.25G [02:59<14:32, 2.10MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "train-00004-of-00014.parquet:  22% 514M/2.30G [03:23<12:54, 2.30MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python setup/download_tokenizer.py llama3 /content/blt/bytelatent/tokenizers --api_key XXXX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADzt_d14lRpc",
        "outputId": "ff55edb1-8073-4364-ef36-7e3a70544c1c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:933: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
            "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
            "  warnings.warn(\n",
            "tokenizer.model: 100% 2.18M/2.18M [00:00<00:00, 7.43MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m bytelatent.stool script=bytelatent.train config=bytelatent/configs/debug.yaml nodes=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGSMOA-In9Nf",
        "outputId": "f48cdb8e-15b8-4622-cf0c-2637c72444bc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/sh: 1: sinfo: not found\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/content/blt/bytelatent/stool.py\", line 237, in <module>\n",
            "    launch_job(args)\n",
            "  File \"/content/blt/bytelatent/stool.py\", line 153, in launch_job\n",
            "    validate_args(args)\n",
            "  File \"/content/blt/bytelatent/stool.py\", line 110, in validate_args\n",
            "    max_times = retrieve_max_time_per_partition()\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/blt/bytelatent/stool.py\", line 91, in retrieve_max_time_per_partition\n",
            "    sinfo = json.loads(subprocess.check_output(\"sinfo --json\", shell=True))[\"sinfo\"]\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/subprocess.py\", line 466, in check_output\n",
            "    return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/subprocess.py\", line 571, in run\n",
            "    raise CalledProcessError(retcode, process.args,\n",
            "subprocess.CalledProcessError: Command 'sinfo --json' returned non-zero exit status 127.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/blt\n",
        "!bash /content/blt/dev/lint.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJj7A2e-oKmx",
        "outputId": "e05a289b-4630-4b9a-bcdd-3eae86b700ec"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/blt\n",
            "/content/blt/dev/lint.sh: line 2: isort: command not found\n",
            "/content/blt/dev/lint.sh: line 3: black: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python demo.py \"A BLT has\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZc37DeFoM5G",
        "outputId": "6e66434a-2bd3-42c2-902d-805062785902"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/blt/\u001b[0m\u001b[1;33mdemo.py\u001b[0m:\u001b[94m17\u001b[0m in \u001b[92mmain\u001b[0m                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m14 \u001b[0m\u001b[2m│   \u001b[0mdistributed_args = DistributedArgs()                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m15 \u001b[0m\u001b[2m│   \u001b[0mdistributed_args.configure_world()                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m16 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m torch.distributed.is_initialized():                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m17 \u001b[2m│   │   \u001b[0m\u001b[1;4msetup_torch_distributed(distributed_args)\u001b[0m                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m18 \u001b[0m\u001b[2m│   \u001b[0mcheckpoint_path = os.path.join(\u001b[33m\"\u001b[0m\u001b[33mhf-weights\u001b[0m\u001b[33m\"\u001b[0m, model_name)            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m19 \u001b[0m\u001b[2m│   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mLoading BLT model: \u001b[0m\u001b[33m{\u001b[0mmodel_name\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m)                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m20 \u001b[0m\u001b[2m│   \u001b[0mmodel, tokenizer, train_cfg = load_consolidated_model_and_tokenizer \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m─────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m──────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m distributed_args = \u001b[1;35mDistributedArgs\u001b[0m\u001b[1m(\u001b[0m                                 \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mdp_shard\u001b[0m=\u001b[94m1\u001b[0m,                                  \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mdp_replicate\u001b[0m=\u001b[94m1\u001b[0m,                              \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mtp_size\u001b[0m=\u001b[94m1\u001b[0m,                                   \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mselective_activation_checkpointing\u001b[0m=\u001b[94mFalse\u001b[0m,    \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mcompile\u001b[0m=\u001b[94mFalse\u001b[0m,                               \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mfsdp_type\u001b[0m=\u001b[33m'no_shard'\u001b[0m,                        \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mmodel_dtype\u001b[0m=\u001b[33m'bf16'\u001b[0m,                          \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mfloat8_recipe\u001b[0m=\u001b[94mNone\u001b[0m,                          \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mfloat8_filter\u001b[0m=\u001b[33m'layers\\\\.\u001b[0m\u001b[1;33m[\u001b[0m\u001b[33m0-9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[33m+\\\\.'\u001b[0m,          \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mmatmul_allow_tf32\u001b[0m=\u001b[94mFalse\u001b[0m,                     \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mallow_bf16_reduced_precision_reduction\u001b[0m=\u001b[94mTrue\u001b[0m, \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mdetect_anomaly\u001b[0m=\u001b[94mFalse\u001b[0m,                        \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mcompile_cache_size_limit\u001b[0m=\u001b[94m8\u001b[0m,                  \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[2m│   \u001b[0m\u001b[33mspawn_method\u001b[0m=\u001b[33m'forkserver'\u001b[0m                    \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    \u001b[1m)\u001b[0m                                                \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m       model_name = \u001b[33m'blt-1b'\u001b[0m                                         \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m           prompt = \u001b[33m'A BLT has'\u001b[0m                                      \u001b[33m│\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰─────────────────────────────────────────────────────────────────────╯\u001b[0m      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/blt/bytelatent/\u001b[0m\u001b[1;33mdistributed.py\u001b[0m:\u001b[94m338\u001b[0m in \u001b[92msetup_torch_distributed\u001b[0m        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m335 \u001b[0m\u001b[2m│   \u001b[0m)                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m336 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m torch.cuda.device_count() > \u001b[94m1\u001b[0m:                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m337 \u001b[0m\u001b[2m│   │   \u001b[0mtorch.cuda.set_device(local_rank)                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m338 \u001b[2m│   \u001b[0m\u001b[1;4mtorch.distributed.init_process_group(init_method=\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4;33menv://\u001b[0m\u001b[1;4;33m\"\u001b[0m\u001b[1;4m, backend\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m339 \u001b[0m\u001b[2m│   \u001b[0mtorch.autograd.set_detect_anomaly(dist_args.detect_anomaly)        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m340 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m341 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m──────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m───────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m  dist_args = \u001b[1;35mDistributedArgs\u001b[0m\u001b[1m(\u001b[0m                                 \u001b[33m│\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              \u001b[2m│   \u001b[0m\u001b[33mdp_shard\u001b[0m=\u001b[94m1\u001b[0m,                                  \u001b[33m│\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              \u001b[2m│   \u001b[0m\u001b[33mdp_replicate\u001b[0m=\u001b[94m1\u001b[0m,                              \u001b[33m│\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              \u001b[2m│   \u001b[0m\u001b[33mtp_size\u001b[0m=\u001b[94m1\u001b[0m,                                   \u001b[33m│\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              \u001b[2m│   \u001b[0m\u001b[33mselective_activation_checkpointing\u001b[0m=\u001b[94mFalse\u001b[0m,    \u001b[33m│\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              \u001b[2m│   \u001b[0m\u001b[33mcompile\u001b[0m=\u001b[94mFalse\u001b[0m,                               \u001b[33m│\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              \u001b[2m│   \u001b[0m\u001b[33mfsdp_type\u001b[0m=\u001b[33m'no_shard'\u001b[0m,                        \u001b[33m│\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              \u001b[2m│   \u001b[0m\u001b[33mmodel_dtype\u001b[0m=\u001b[33m'bf16'\u001b[0m,                          \u001b[33m│\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              \u001b[2m│   \u001b[0m\u001b[33mfloat8_recipe\u001b[0m=\u001b[94mNone\u001b[0m,                          \u001b[33m│\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              \u001b[2m│   \u001b[0m\u001b[33mfloat8_filter\u001b[0m=\u001b[33m'layers\\\\.\u001b[0m\u001b[1;33m[\u001b[0m\u001b[33m0-9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[33m+\\\\.'\u001b[0m,          \u001b[33m│\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              \u001b[2m│   \u001b[0m\u001b[33mmatmul_allow_tf32\u001b[0m=\u001b[94mFalse\u001b[0m,                     \u001b[33m│\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              \u001b[2m│   \u001b[0m\u001b[33mallow_bf16_reduced_precision_reduction\u001b[0m=\u001b[94mTrue\u001b[0m, \u001b[33m│\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              \u001b[2m│   \u001b[0m\u001b[33mdetect_anomaly\u001b[0m=\u001b[94mFalse\u001b[0m,                        \u001b[33m│\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              \u001b[2m│   \u001b[0m\u001b[33mcompile_cache_size_limit\u001b[0m=\u001b[94m8\u001b[0m,                  \u001b[33m│\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              \u001b[2m│   \u001b[0m\u001b[33mspawn_method\u001b[0m=\u001b[33m'forkserver'\u001b[0m                    \u001b[33m│\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m              \u001b[1m)\u001b[0m                                                \u001b[33m│\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m local_rank = \u001b[94m0\u001b[0m                                                \u001b[33m│\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰───────────────────────────────────────────────────────────────╯\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/torch/distributed/\u001b[0m\u001b[1;33mc10d_logger.py\u001b[0m:\u001b[94m83\u001b[0m  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m in \u001b[92mwrapper\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 80 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@functools\u001b[0m.wraps(func)                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 81 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mwrapper\u001b[0m(*args: _P.args, **kwargs: _P.kwargs) -> _T:            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 82 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 83 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwargs)                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 84 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mException\u001b[0m \u001b[94mas\u001b[0m error:                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 85 \u001b[0m\u001b[2m│   │   │   \u001b[0mmsg_dict = _get_msg_dict(func.\u001b[91m__name__\u001b[0m, *args, **kwargs)   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 86 \u001b[0m\u001b[2m│   │   │   \u001b[0mmsg_dict[\u001b[33m\"\u001b[0m\u001b[33merror\u001b[0m\u001b[33m\"\u001b[0m] = \u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m{\u001b[0merror\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     args = \u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                                                            \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m   kwargs = \u001b[1m{\u001b[0m\u001b[33m'init_method'\u001b[0m: \u001b[33m'env://'\u001b[0m, \u001b[33m'backend'\u001b[0m: \u001b[33m'nccl'\u001b[0m\u001b[1m}\u001b[0m                  \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m msg_dict = \u001b[1m{\u001b[0m                                                             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            \u001b[2m│   \u001b[0m\u001b[33m'func_name'\u001b[0m: \u001b[33m'init_process_group'\u001b[0m,                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            \u001b[2m│   \u001b[0m\u001b[33m'args'\u001b[0m: \u001b[33m\"\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m{\u001b[0m\u001b[33m'init_method': 'env://', 'backend': \u001b[0m        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            \u001b[33m'nccl'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[33m\"\u001b[0m,                                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            \u001b[2m│   \u001b[0m\u001b[33m'error'\u001b[0m: \u001b[33m'ProcessGroupNCCL is only supported with GPUs, \u001b[0m  \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            \u001b[33mno GPUs found!'\u001b[0m                                               \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            \u001b[1m}\u001b[0m                                                             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/torch/distributed/\u001b[0m\u001b[1;33mc10d_logger.py\u001b[0m:\u001b[94m97\u001b[0m  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m in \u001b[92mwrapper\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 94 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@functools\u001b[0m.wraps(func)                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 95 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mwrapper\u001b[0m(*args: _P.args, **kwargs: _P.kwargs) -> _T:            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 96 \u001b[0m\u001b[2m│   │   \u001b[0mt1 = time.time_ns()                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 97 \u001b[2m│   │   \u001b[0mfunc_return = \u001b[1;4mfunc(*args, **kwargs)\u001b[0m                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 98 \u001b[0m\u001b[2m│   │   \u001b[0mtime_spent = time.time_ns() - t1                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 99 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m100 \u001b[0m\u001b[2m│   │   \u001b[0mmsg_dict = _get_msg_dict(func.\u001b[91m__name__\u001b[0m, *args, **kwargs)       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m──────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m───────────────────────\u001b[0m\u001b[33m─╮\u001b[0m                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m   args = \u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                                           \u001b[33m│\u001b[0m                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m kwargs = \u001b[1m{\u001b[0m\u001b[33m'init_method'\u001b[0m: \u001b[33m'env://'\u001b[0m, \u001b[33m'backend'\u001b[0m: \u001b[33m'nccl'\u001b[0m\u001b[1m}\u001b[0m \u001b[33m│\u001b[0m                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m     t1 = \u001b[94m1745378041697338389\u001b[0m                          \u001b[33m│\u001b[0m                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰───────────────────────────────────────────────────────╯\u001b[0m                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/torch/distributed/\u001b[0m\u001b[1;33mdistributed_c10d.p\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[1;33my\u001b[0m:\u001b[94m1527\u001b[0m in \u001b[92minit_process_group\u001b[0m                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1524 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# different systems (e.g. RPC) in case the store is multi\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1525 \u001b[0m\u001b[2m│   │   │   \u001b[0mstore = PrefixStore(\u001b[33m\"\u001b[0m\u001b[33mdefault_pg\u001b[0m\u001b[33m\"\u001b[0m, store)                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1526 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1527 \u001b[2m│   │   \u001b[0mdefault_pg, _ = _new_process_group_helper(                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1528 \u001b[0m\u001b[2m│   │   │   \u001b[0mworld_size,                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1529 \u001b[0m\u001b[2m│   │   │   \u001b[0mrank,                                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1530 \u001b[0m\u001b[2m│   │   │   \u001b[0m[],                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m             backend = \u001b[33m'nccl'\u001b[0m                                             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m           device_id = \u001b[94mNone\u001b[0m                                               \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          group_name = \u001b[33m'0'\u001b[0m                                                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m         init_method = \u001b[33m'env://'\u001b[0m                                           \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          pg_options = \u001b[94mNone\u001b[0m                                               \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                rank = \u001b[94m0\u001b[0m                                                  \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m rendezvous_iterator = \u001b[1m<\u001b[0m\u001b[1;95mgenerator\u001b[0m\u001b[39m object _env_rendezvous_handler at \u001b[0m      \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                       \u001b[94m0x1081ff3e9220\u001b[0m\u001b[1m>\u001b[0m                                    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m               store = \u001b[1m<\u001b[0m\u001b[1;95mtorch.distributed.distributed_c10d.PrefixStore\u001b[0m\u001b[39m \u001b[0m   \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                       \u001b[39mobject at \u001b[0m\u001b[94m0x1081ff2329b0\u001b[0m\u001b[1m>\u001b[0m                          \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m             timeout = \u001b[1;35mdatetime.timedelta\u001b[0m\u001b[1m(\u001b[0m\u001b[33mseconds\u001b[0m=\u001b[94m600\u001b[0m\u001b[1m)\u001b[0m                    \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          world_size = \u001b[94m1\u001b[0m                                                  \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.11/dist-packages/torch/distributed/\u001b[0m\u001b[1;33mdistributed_c10d.p\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[1;33my\u001b[0m:\u001b[94m1771\u001b[0m in \u001b[92m_new_process_group_helper\u001b[0m                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1768 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mpg_options.split_color = _process_group_color(global_ \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1769 \u001b[0m\u001b[2m│   │   │   \u001b[0mpg_options.global_ranks_in_group = global_ranks_in_group  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1770 \u001b[0m\u001b[2m│   │   │   \u001b[0mpg_options.group_name = group_name                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1771 \u001b[2m│   │   │   \u001b[0mbackend_class = \u001b[1;4mProcessGroupNCCL(\u001b[0m                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1772 \u001b[0m\u001b[1;2;4m│   │   │   │   \u001b[0m\u001b[1;4mbackend_prefix_store, group_rank, group_size, pg_opti\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1773 \u001b[0m\u001b[1;2;4m│   │   │   \u001b[0m\u001b[1;4m)\u001b[0m                                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1774 \u001b[0m\u001b[2m│   │   │   \u001b[0mbackend_type = ProcessGroup.BackendType.NCCL              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╭─\u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m locals \u001b[0m\u001b[33m────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m               backend = \u001b[33m'nccl'\u001b[0m                                           \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m        backend_config = cuda:nccl                                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m  backend_prefix_store = \u001b[1m<\u001b[0m\u001b[1;95mtorch.distributed.distributed_c10d.PrefixStore\u001b[0m\u001b[39m \u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                         \u001b[39mobject at \u001b[0m\u001b[94m0x1081ff232bf0\u001b[0m\u001b[1m>\u001b[0m                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m           backend_str = \u001b[33m'nccl'\u001b[0m                                           \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m       base_pg_options = \u001b[1m<\u001b[0m\u001b[1;95mtorch._C._distributed_c10d.ProcessGroup.Options\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                         \u001b[39mobject at \u001b[0m\u001b[94m0x1081ff232a70\u001b[0m\u001b[1m>\u001b[0m                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                device = \u001b[33m'cuda'\u001b[0m                                           \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m             device_id = \u001b[94mNone\u001b[0m                                             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m global_ranks_in_group = \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m                                               \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            group_desc = \u001b[33m'default_pg'\u001b[0m                                     \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            group_name = \u001b[33m'0'\u001b[0m                                              \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            group_rank = \u001b[94m0\u001b[0m                                                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            group_size = \u001b[94m1\u001b[0m                                                \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m      is_default_group = \u001b[94mTrue\u001b[0m                                             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                    pg = \u001b[1m<\u001b[0m\u001b[1;95mtorch.distributed.distributed_c10d.ProcessGroup\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                         \u001b[39mobject at \u001b[0m\u001b[94m0x1081ff232ab0\u001b[0m\u001b[1m>\u001b[0m                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            pg_options = \u001b[1m<\u001b[0m\u001b[1;95mtorch._C._distributed_c10d.ProcessGroupNCCL.Op…\u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                         \u001b[39mobject at \u001b[0m\u001b[94m0x1081ff232bb0\u001b[0m\u001b[1m>\u001b[0m                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                pg_tag = \u001b[94mNone\u001b[0m                                             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m          prefix_store = \u001b[1m<\u001b[0m\u001b[1;95mtorch.distributed.distributed_c10d.PrefixStore\u001b[0m\u001b[39m \u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                         \u001b[39mobject at \u001b[0m\u001b[94m0x1081ff2329f0\u001b[0m\u001b[1m>\u001b[0m                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m            split_from = \u001b[94mNone\u001b[0m                                             \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                 store = \u001b[1m<\u001b[0m\u001b[1;95mtorch.distributed.distributed_c10d.PrefixStore\u001b[0m\u001b[39m \u001b[0m \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m                         \u001b[39mobject at \u001b[0m\u001b[94m0x1081ff2329b0\u001b[0m\u001b[1m>\u001b[0m                        \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m│\u001b[0m               timeout = \u001b[1;35mdatetime.timedelta\u001b[0m\u001b[1m(\u001b[0m\u001b[33mseconds\u001b[0m=\u001b[94m600\u001b[0m\u001b[1m)\u001b[0m                  \u001b[33m│\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[33m╰──────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\u001b[1;91mValueError: \u001b[0mProcessGroupNCCL is only supported with GPUs, no GPUs found!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\"facebook/blt\", device_map=\"auto\", quantization_config=quantization_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "XfhUbg0qov32",
        "outputId": "218d0137-f17e-49e7-d398-981752c3bc6d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "PackageNotFoundError",
          "evalue": "No package metadata was found for bitsandbytes",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.11/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mfrom_name\u001b[0;34m(cls, name)\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mStopIteration\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mPackageNotFoundError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-d12b650e8abf>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBitsAndBytesConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mquantization_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBitsAndBytesConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_in_4bit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"facebook/blt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantization_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquantization_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/quantization_config.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, load_in_8bit, load_in_4bit, llm_int8_threshold, llm_int8_skip_modules, llm_int8_enable_fp32_cpu_offload, llm_int8_has_fp16_weight, bnb_4bit_compute_dtype, bnb_4bit_quant_type, bnb_4bit_use_double_quant, bnb_4bit_quant_storage, **kwargs)\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unused kwargs: {list(kwargs.keys())}. These kwargs are not used in {self.__class__}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/quantization_config.py\u001b[0m in \u001b[0;36mpost_init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bnb_4bit_use_double_quant must be a boolean\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         if self.load_in_4bit and not version.parse(importlib.metadata.version(\"bitsandbytes\")) >= version.parse(\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;34m\"0.39.0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         ):\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mversion\u001b[0;34m(distribution_name)\u001b[0m\n\u001b[1;32m   1007\u001b[0m         \u001b[0;34m\"Version\"\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \"\"\"\n\u001b[0;32m-> 1009\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistribution_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mdistribution\u001b[0;34m(distribution_name)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDistribution\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mor\u001b[0m \u001b[0msubclass\u001b[0m \u001b[0mthereof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m     \"\"\"\n\u001b[0;32m--> 982\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistribution_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mfrom_name\u001b[0;34m(cls, name)\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPackageNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPackageNotFoundError\u001b[0m: No package metadata was found for bitsandbytes",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pOJsT0Fvpx_H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}